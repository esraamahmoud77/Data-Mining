{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8UzJdmzwwtN"
      },
      "source": [
        "# Problem Formulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e3wY2jNxza-"
      },
      "source": [
        ">**The problem:** \n",
        "\n",
        "This is a bioassay task for anticancer activity prediction, where we need to know if  the chemical compound is positive against non-small cell lung cancer, or negative otherwise.\n",
        "\n",
        ">**input:**\n",
        "\n",
        "A dataset where each chemical compound is represented as a graph, with atoms representing nodes and bonds as edges.The input file is structure data file (SDF).\n",
        "\n",
        ">**output:**\n",
        "\n",
        "Predictions of anticancer activity prediction task (labels) where:\n",
        "* 1 means possitive\n",
        "* 0 means negative\n",
        "\n",
        "\n",
        ">**Data Minning Function**\n",
        "\n",
        "This is a classification & prediction task.\n",
        "\n",
        "\n",
        ">**The challanges could be**\n",
        "\n",
        "dealing with SDF format, dealing with graphs, feature selection, feature engineering, not enough training data, data imbalance, overfitting or underfitting.\n",
        "\n",
        "\n",
        "> **The impact:**\n",
        "\n",
        "This can be very useful application of finding the best treatment for lung cancer patients, and in general this could save e lot of effort and time for patients with cancer instead of trying many treatment protocols on them which is very exhausting process.\n",
        "\n",
        "\n",
        "\n",
        "> **The ideal solution**\n",
        "\n",
        "is to select and design a machine learning model that predict the best chemical compund that is most effective in lung cancer treatment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC73uW7J1m8V"
      },
      "source": [
        "# Questions â“"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icJjZoFY1upo"
      },
      "source": [
        "> ğŸŒˆ Based on the provided template, describe the format of the input file (sdf file).\n",
        "\n",
        "* It's a chemical-data file formats that contains multiple records delimited by lines consisting of four dollar signs `$$$$`. It stores multiple molecules in a single file .It also store information about position of chemical compound atoms and the connections betwwen them.\n",
        "\n",
        "* Each molecule starts with the name of the compound. Other sections includes information about Atom count, version number, edge connections.\n",
        "- 1st block is atom block contains elements of the compound (nodes).\n",
        "- 2nd block is bond block contains the bonds between atoms of the compound (edges). \n",
        "\n",
        "> ğŸŒˆ What are the input tensors to the neural network model (their meaning, not just symbol)? What is each of their dims and their meaning (e.g. batch_size)?\n",
        "\n",
        "The input tensors in this network are:\n",
        "\n",
        "* data: It contains the tokenized chemical compound atoms(nodes). Each compound's nodes are retrieved, tokenized with the help of a tokenizer, and then padded using the pad_sequence technique. Each batch has the shape [batch_size*max_len_nodes], where `batch_size` denotes the number of samples in the batch and `max_len_nodes` denotes the length of tokenized nodes following padding.\n",
        "\n",
        "* edge: It's the input tensor thatÂ contains information on atom connections. Edges have the shape [sum_of_all_edges,2]. The number of edges in each sample is represented by the total of all edges, or batch size.\n",
        "\n",
        "* node2graph: This input tensor, which provides details about segmented ids, is used for segmented mean. Each batch has the shape [batch_size*max_len_nodes], where `batch_size` denotes the number of samples in the batch and `max_len_nodes` denotes the length of tokenized nodes following padding.\n",
        "\n",
        "> ğŸŒˆ For each dim of gnn_out, what does it symbolize? For each dim of avg, what does it symbolize?\n",
        "\n",
        "* gnn_out: The shape of the `gnn_out` is [batch_size_node_dimension,hidden layers], where `batch_size_node_dimension` is the dimension of the input data (node) vector (dimension of tokenized vector for the entire batch). It represents the model's aggregation output for each hidden layer.\n",
        "\n",
        "*  avg: Average computes the segmented mean of the `gnn_out` based on the segmented ids. The output of `gnn_out` for each sample in the `batch_size` is [tokenized_vector_dimension, hidden_layers]. Each sample has a unique segment id. Thus, `segment_mean` takes the mean of all the output data in the `gnn_out` output and represents one sample with one number for each hidden layer. The average tensor's final output is of the form [batch_size, hidden_layer]. It is a method of collecting information for each sample and presenting it as mean data.\n",
        "\n",
        "\n",
        "> ğŸŒˆ What is the difference between segment_mean and tf.reduce_mean? For each dim of pred, what does it symbolize?\n",
        "\n",
        "* segment_mean computes the mean of data with the same segmented ids.\n",
        "\n",
        "* reduce_mean: computes the mean of a tensor's elements across dimensions given the parameters.\n",
        "  - To calculate the mean of tensor elements along various dimensions of the tensor, we used the TensorFlow reduce_mean method.\n",
        "\n",
        "* pred: The final output (pred) indicates whether a chemical substance is active for cancer cells or not. Pred has the shape [batch_size,1]. Thus, the final output for each sample is a number that represents the probability of each chemical compound's activity.\n",
        "\n",
        "> ğŸŒˆ What is the motivation/theory/idea to use multiple gcn layers comparing to just one? How many layers were used in the template?\n",
        "\n",
        "* As Graph Convolutional Networks (GCNs) are a type of neural network that can operate on graph-structured data such as social networks or citation networks. By stacking multiple GCN layers, the information can be propagated across far reaches of a graph, which makes GCNs capable of learning from both content information as well as graph structure. In particular, GCN has a powerful ability to model higher-order neighborhood interactions by stacking multiple layers. Therefore, using multiple GCN layers can help capture more complex patterns in the data and improve the performance of the model.\n",
        "\n",
        "* 4 layers were used in thr=e template  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxDD8tJrKJf_"
      },
      "source": [
        "# Implementation â­"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiIjDA2jLn8v"
      },
      "source": [
        "## Important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WOIa8F7LM38",
        "outputId": "57a04e3e-48b5-4145-ff74-2101b34a7826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHSvljdCLDwQ",
        "outputId": "93cdd34c-1284-49cf-8dc7-412ccb096490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m135.5/135.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m173.9/173.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for tf2_gnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet tf2_gnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vYlRLBWjKcXO"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, precision_score, recall_score, f1_score, precision_recall_curve\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import math\n",
        "sns.set()\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from time import time\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import resample \n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Embedding, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten, Dropout\n",
        "from tensorflow.keras.layers import GRU, LSTM, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tf2_gnn.layers.gnn import GNN, GNNInput\n",
        "from tf2_gnn.layers.message_passing import GNN_Edge_MLP, GNN_FiLM\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 300\n",
        "pd.options.display.max_colwidth = 100\n",
        "np.set_printoptions(threshold=2000)\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        "random.seed(10)\n",
        "\n",
        "!pip install --quiet tf2_gnn\n",
        "from tf2_gnn.layers.gnn import GNN, GNNInput"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBvaCsMDMP4O"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1I63xQCzNA78"
      },
      "outputs": [],
      "source": [
        "# A function to read sdf files\n",
        "\n",
        "def read_sdf(file):\n",
        "    with open(file, 'r') as rf:\n",
        "        content = rf.read()\n",
        "    samples = content.split('$$$$') ## split values by '$$$$' and put them in a list\n",
        "\n",
        "\n",
        "## A function to analyze the file content (samples)\n",
        "    def parse_sample(s):\n",
        "        lines = s.splitlines() ## divide it to lines\n",
        "        links = []            ## a list to contain edges\n",
        "        nodes = []\n",
        "        label = 0\n",
        "        for l in lines:\n",
        "          # label conversion\n",
        "            if l.strip() == '1.0':\n",
        "                label = 1\n",
        "            if l.strip() == '-1.0':\n",
        "                label = 0\n",
        "              # lines of nodes starts with 4 spaces\n",
        "            if l.startswith('    '):\n",
        "                feature = l.split()\n",
        "                node = feature[3]  # the symbols of chemical elements\n",
        "                nodes.append(node)\n",
        "              # lines of edges starts with 2 spaces\n",
        "            elif l.startswith(' '):\n",
        "                lnk = l.split()\n",
        "                # edge: (from, to,) (1-based index)\n",
        "                if int(lnk[0]) - 1 < len(nodes):\n",
        "                    links.append((\n",
        "                        int(lnk[0])-1, \n",
        "                        int(lnk[1])-1, # zero-based index\n",
        "                        # int(lnk[2]) ignore edge weight\n",
        "                    ))\n",
        "        return nodes, np.array(links), label\n",
        "    \n",
        "    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "a918a40a5f1c4f90a0a3228756b98aa4",
            "83de2a2a31d4470abcfd8effb9dde815",
            "4703adaa0e934693ac93ef83cda18391",
            "8bab2f05b04e4daa8516dacf906a05c2",
            "90f08749c2c04066be6f54527a8c37a0",
            "54298f85799a4ba28f42b84b99300550",
            "e8e8becc624a45b691c188849b485f65",
            "a74a20e9a7d8456db86ed91de1dd6315",
            "8fb16eaa4319457f9f3551bd96166af7",
            "b3862bd8e79a4998b0dda0a2bb723581",
            "05f72766539c4ef8b618a8875d1d364c",
            "5da15f791090436b82d79229096abac8",
            "110d35abed8c4a498a7141b6481aa158",
            "9f542dd37a8e4753948a95d103dc88f4",
            "226036de4a0a4fc59aa579abc4e21939",
            "9ee980dc1cb141bcac14e72d53e62300",
            "0cf1bf1305274760a3ba0eb8247a3d91",
            "fdf0968e008e4091b47cec0593311c24",
            "246971be9b8a40359611a46c7254eef2",
            "6c99511dfc7c490b93c30341882dd729",
            "9533476c6fdd4e1fbe32cb14a7a41b5d",
            "ac8f51474ec347589bac8f71968a8eab"
          ]
        },
        "id": "DoEboSakMaYO",
        "outputId": "c802c2dc-d34f-4cba-e7f3-bf067d0aee00"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a918a40a5f1c4f90a0a3228756b98aa4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25024 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5da15f791090436b82d79229096abac8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12326 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train = read_sdf('/content/gdrive/MyDrive/competition 5/train.sdf')\n",
        "test = read_sdf('/content/gdrive/MyDrive/competition 5/test_x.sdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RTt16pWMhji",
        "outputId": "a891ef5d-39aa-426d-897b-7d46b04a736f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(['S', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0,  8],\n",
            "       [ 0, 14],\n",
            "       [ 1, 10],\n",
            "       [ 2, 11],\n",
            "       [ 3,  7],\n",
            "       [ 4,  7],\n",
            "       [ 5,  9],\n",
            "       [ 5, 14],\n",
            "       [ 6, 14],\n",
            "       [ 6, 17],\n",
            "       [ 7, 22],\n",
            "       [ 8,  9],\n",
            "       [ 8, 10],\n",
            "       [ 9, 11],\n",
            "       [10, 12],\n",
            "       [11, 13],\n",
            "       [12, 13],\n",
            "       [12, 15],\n",
            "       [13, 16],\n",
            "       [15, 18],\n",
            "       [16, 19],\n",
            "       [17, 20],\n",
            "       [17, 21],\n",
            "       [18, 19],\n",
            "       [20, 23],\n",
            "       [21, 24],\n",
            "       [22, 23],\n",
            "       [22, 24]]), 0), (['O', 'O', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0,  6],\n",
            "       [ 0, 15],\n",
            "       [ 1, 15],\n",
            "       [ 2,  7],\n",
            "       [ 3,  8],\n",
            "       [ 4,  7],\n",
            "       [ 5,  8],\n",
            "       [ 6,  9],\n",
            "       [ 7, 16],\n",
            "       [ 8, 17],\n",
            "       [ 9, 10],\n",
            "       [ 9, 11],\n",
            "       [10, 12],\n",
            "       [10, 22],\n",
            "       [11, 13],\n",
            "       [11, 23],\n",
            "       [12, 21],\n",
            "       [12, 25],\n",
            "       [13, 20],\n",
            "       [13, 26],\n",
            "       [14, 15],\n",
            "       [14, 18],\n",
            "       [14, 19],\n",
            "       [16, 19],\n",
            "       [16, 24],\n",
            "       [17, 18],\n",
            "       [17, 24],\n",
            "       [20, 21],\n",
            "       [22, 27],\n",
            "       [23, 28],\n",
            "       [25, 29],\n",
            "       [26, 30],\n",
            "       [27, 29],\n",
            "       [28, 30]]), 0), (['F', 'F', 'F', 'O', 'O', 'O', 'O', 'O', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0, 19],\n",
            "       [ 1, 19],\n",
            "       [ 2, 19],\n",
            "       [ 3, 16],\n",
            "       [ 4, 28],\n",
            "       [ 4, 32],\n",
            "       [ 5, 28],\n",
            "       [ 6, 29],\n",
            "       [ 6, 33],\n",
            "       [ 7, 29],\n",
            "       [ 8, 10],\n",
            "       [ 8, 13],\n",
            "       [ 8, 16],\n",
            "       [ 9, 12],\n",
            "       [ 9, 18],\n",
            "       [10, 11],\n",
            "       [10, 12],\n",
            "       [11, 14],\n",
            "       [11, 20],\n",
            "       [12, 15],\n",
            "       [13, 14],\n",
            "       [13, 21],\n",
            "       [14, 22],\n",
            "       [15, 17],\n",
            "       [15, 23],\n",
            "       [16, 19],\n",
            "       [17, 18],\n",
            "       [17, 24],\n",
            "       [18, 25],\n",
            "       [20, 28],\n",
            "       [21, 26],\n",
            "       [22, 27],\n",
            "       [23, 29],\n",
            "       [24, 30],\n",
            "       [25, 31],\n",
            "       [26, 27],\n",
            "       [30, 31]]), 0), (['Cl', 'S', 'S', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0, 12],\n",
            "       [ 1, 15],\n",
            "       [ 1, 18],\n",
            "       [ 2,  4],\n",
            "       [ 2,  5],\n",
            "       [ 2,  6],\n",
            "       [ 2, 23],\n",
            "       [ 3, 13],\n",
            "       [ 7, 11],\n",
            "       [ 7, 13],\n",
            "       [ 7, 15],\n",
            "       [ 8,  9],\n",
            "       [ 8, 11],\n",
            "       [ 8, 17],\n",
            "       [ 9, 16],\n",
            "       [10, 15],\n",
            "       [10, 19],\n",
            "       [11, 12],\n",
            "       [11, 14],\n",
            "       [12, 13],\n",
            "       [14, 16],\n",
            "       [16, 22],\n",
            "       [17, 20],\n",
            "       [17, 21],\n",
            "       [18, 19],\n",
            "       [18, 26],\n",
            "       [19, 27],\n",
            "       [20, 24],\n",
            "       [21, 25],\n",
            "       [23, 24],\n",
            "       [23, 25],\n",
            "       [26, 28],\n",
            "       [27, 29],\n",
            "       [28, 29]]), 0), (['S', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0,  1],\n",
            "       [ 0,  2],\n",
            "       [ 0,  5],\n",
            "       [ 0,  9],\n",
            "       [ 3,  4],\n",
            "       [ 3, 10],\n",
            "       [ 4, 16],\n",
            "       [ 6, 13],\n",
            "       [ 6, 18],\n",
            "       [ 7, 17],\n",
            "       [ 7, 19],\n",
            "       [ 8, 16],\n",
            "       [ 9, 11],\n",
            "       [ 9, 12],\n",
            "       [10, 14],\n",
            "       [10, 15],\n",
            "       [11, 14],\n",
            "       [12, 15],\n",
            "       [13, 16],\n",
            "       [13, 17],\n",
            "       [18, 19]]), 0), (['O', 'O', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0,  9],\n",
            "       [ 0, 13],\n",
            "       [ 1,  8],\n",
            "       [ 2,  8],\n",
            "       [ 2,  9],\n",
            "       [ 2, 12],\n",
            "       [ 3,  7],\n",
            "       [ 3,  9],\n",
            "       [ 4,  6],\n",
            "       [ 4, 10],\n",
            "       [ 5,  7],\n",
            "       [ 5, 11],\n",
            "       [ 6,  7],\n",
            "       [ 6,  8],\n",
            "       [10, 11]]), 0), (['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0, 29],\n",
            "       [ 0, 43],\n",
            "       [ 1, 33],\n",
            "       [ 1, 39],\n",
            "       [ 2, 34],\n",
            "       [ 2, 44],\n",
            "       [ 3, 31],\n",
            "       [ 3, 48],\n",
            "       [ 4, 41],\n",
            "       [ 4, 42],\n",
            "       [ 5, 42],\n",
            "       [ 5, 60],\n",
            "       [ 6, 53],\n",
            "       [ 6, 57],\n",
            "       [ 7, 35],\n",
            "       [ 8, 38],\n",
            "       [ 9, 39],\n",
            "       [10, 43],\n",
            "       [11, 44],\n",
            "       [12, 46],\n",
            "       [13, 48],\n",
            "       [14, 49],\n",
            "       [15, 50],\n",
            "       [16, 51],\n",
            "       [17, 53],\n",
            "       [18, 55],\n",
            "       [19, 56],\n",
            "       [20, 59],\n",
            "       [21, 60],\n",
            "       [22, 61],\n",
            "       [23, 61],\n",
            "       [24, 65],\n",
            "       [25, 66],\n",
            "       [26, 67],\n",
            "       [27, 28],\n",
            "       [27, 29],\n",
            "       [27, 30],\n",
            "       [28, 32],\n",
            "       [28, 35],\n",
            "       [29, 38],\n",
            "       [30, 39],\n",
            "       [30, 45],\n",
            "       [31, 33],\n",
            "       [31, 34],\n",
            "       [32, 44],\n",
            "       [32, 54],\n",
            "       [33, 42],\n",
            "       [34, 41],\n",
            "       [35, 43],\n",
            "       [36, 37],\n",
            "       [36, 40],\n",
            "       [36, 49],\n",
            "       [37, 47],\n",
            "       [37, 50],\n",
            "       [38, 46],\n",
            "       [40, 48],\n",
            "       [40, 52],\n",
            "       [41, 57],\n",
            "       [45, 46],\n",
            "       [47, 53],\n",
            "       [47, 58],\n",
            "       [49, 51],\n",
            "       [50, 55],\n",
            "       [51, 56],\n",
            "       [52, 56],\n",
            "       [54, 61],\n",
            "       [55, 59],\n",
            "       [58, 59],\n",
            "       [60, 62],\n",
            "       [62, 63],\n",
            "       [62, 64],\n",
            "       [63, 66],\n",
            "       [64, 65],\n",
            "       [65, 67],\n",
            "       [66, 67]]), 0)]\n"
          ]
        }
      ],
      "source": [
        "# check data \n",
        "print(train[0:7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGU_N_m6QtI-"
      },
      "source": [
        "## Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HVjKung-QwcD"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FhZvu7_6Q1xQ"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "colors = cm.Spectral(np.linspace(0, 1, 70))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zkTwXJ8NRr-_"
      },
      "outputs": [],
      "source": [
        "# A function to visualize samples\n",
        "def visualize(sample):\n",
        "  # Graph instance\n",
        "    graph=nx.Graph()\n",
        "    nodes = sample[0]  # fisrt feature is nodes\n",
        "    edges = sample[1]  # second feature is edges\n",
        "\n",
        "    # A dictionary to represent node symbols with numbers \n",
        "    labeldict={}\n",
        "    node_color=[]\n",
        "    for i,n in enumerate(nodes):\n",
        "        graph.add_node(i)\n",
        "        labeldict[i]=n\n",
        "        # color coding for each node\n",
        "        node_color.append(colors[hash(n)%len(colors)])\n",
        "\n",
        "    # a list of nodes:\n",
        "    for e in edges:\n",
        "        graph.add_edge(e[0], e[1])\n",
        "        \n",
        "    nx.draw_networkx(graph, labels=labeldict, with_labels = True, node_color = node_color)\n",
        "    plt.show()\n",
        "    \n",
        "    return graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "E0pTwALZTTrX",
        "outputId": "ddf6be27-7cbc-4f3b-ff09-f0f372b5d73d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x7f45e6633a30>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plt.clf()\n",
        "visualize(train[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4f1ZEQDuTgeF"
      },
      "outputs": [],
      "source": [
        "# convert train into DataFrame\n",
        "train_df = pd.DataFrame(train, columns=['node','edge','label']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "4lINdwi1WAz5",
        "outputId": "a7dbcc60-f542-446f-c186-c738ae6ac0fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0591a8a8-9bce-4751-8e79-66db1c476730\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>node</th>\n",
              "      <th>edge</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[S, O, O, O, O, N, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C]</td>\n",
              "      <td>[[0, 8], [0, 14], [1, 10], [2, 11], [3, 7], [4, 7], [5, 9], [5, 14], [6, 14], [6, 17], [7, 22], ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[O, O, O, O, O, O, N, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C]</td>\n",
              "      <td>[[0, 6], [0, 15], [1, 15], [2, 7], [3, 8], [4, 7], [5, 8], [6, 9], [7, 16], [8, 17], [9, 10], [9...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[F, F, F, O, O, O, O, O, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C,...</td>\n",
              "      <td>[[0, 19], [1, 19], [2, 19], [3, 16], [4, 28], [4, 32], [5, 28], [6, 29], [6, 33], [7, 29], [8, 1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Cl, S, S, O, O, O, O, N, N, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C]</td>\n",
              "      <td>[[0, 12], [1, 15], [1, 18], [2, 4], [2, 5], [2, 6], [2, 23], [3, 13], [7, 11], [7, 13], [7, 15],...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[S, O, O, N, N, N, N, N, N, C, C, C, C, C, C, C, C, C, C, C]</td>\n",
              "      <td>[[0, 1], [0, 2], [0, 5], [0, 9], [3, 4], [3, 10], [4, 16], [6, 13], [6, 18], [7, 17], [7, 19], [...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25019</th>\n",
              "      <td>[O, O, O, O, O, O, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C]</td>\n",
              "      <td>[[0, 8], [0, 14], [1, 10], [2, 12], [3, 13], [4, 7], [5, 7], [6, 8], [6, 9], [6, 15], [7, 18], [...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25020</th>\n",
              "      <td>[O, O, O, O, O, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C]</td>\n",
              "      <td>[[0, 9], [1, 11], [2, 16], [2, 19], [3, 16], [4, 15], [5, 18], [6, 7], [6, 8], [6, 13], [7, 10],...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25021</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C,...</td>\n",
              "      <td>[[0, 12], [0, 16], [1, 10], [2, 11], [3, 15], [4, 16], [5, 17], [6, 18], [6, 27], [7, 20], [8, 2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25022</th>\n",
              "      <td>[S, O, O, O, O, N, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C]</td>\n",
              "      <td>[[0, 11], [0, 12], [1, 21], [1, 27], [2, 22], [2, 28], [3, 21], [4, 22], [5, 8], [5, 12], [6, 13...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25023</th>\n",
              "      <td>[Cl, Cl, Cl, S, O, O, O, O, N, N, N, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C,...</td>\n",
              "      <td>[[0, 25], [1, 26], [2, 29], [3, 13], [3, 15], [4, 14], [5, 24], [6, 12], [7, 12], [8, 13], [8, 1...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25024 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0591a8a8-9bce-4751-8e79-66db1c476730')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0591a8a8-9bce-4751-8e79-66db1c476730 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0591a8a8-9bce-4751-8e79-66db1c476730');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                                      node  \\\n",
              "0                              [S, O, O, O, O, N, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C]   \n",
              "1            [O, O, O, O, O, O, N, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C]   \n",
              "2      [F, F, F, O, O, O, O, O, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C,...   \n",
              "3              [Cl, S, S, O, O, O, O, N, N, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C]   \n",
              "4                                             [S, O, O, N, N, N, N, N, N, C, C, C, C, C, C, C, C, C, C, C]   \n",
              "...                                                                                                    ...   \n",
              "25019                                   [O, O, O, O, O, O, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C]   \n",
              "25020                                      [O, O, O, O, O, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C]   \n",
              "25021  [O, O, O, O, O, O, O, O, O, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C,...   \n",
              "25022        [S, O, O, O, O, N, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C]   \n",
              "25023  [Cl, Cl, Cl, S, O, O, O, O, N, N, N, N, N, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, C,...   \n",
              "\n",
              "                                                                                                      edge  \\\n",
              "0      [[0, 8], [0, 14], [1, 10], [2, 11], [3, 7], [4, 7], [5, 9], [5, 14], [6, 14], [6, 17], [7, 22], ...   \n",
              "1      [[0, 6], [0, 15], [1, 15], [2, 7], [3, 8], [4, 7], [5, 8], [6, 9], [7, 16], [8, 17], [9, 10], [9...   \n",
              "2      [[0, 19], [1, 19], [2, 19], [3, 16], [4, 28], [4, 32], [5, 28], [6, 29], [6, 33], [7, 29], [8, 1...   \n",
              "3      [[0, 12], [1, 15], [1, 18], [2, 4], [2, 5], [2, 6], [2, 23], [3, 13], [7, 11], [7, 13], [7, 15],...   \n",
              "4      [[0, 1], [0, 2], [0, 5], [0, 9], [3, 4], [3, 10], [4, 16], [6, 13], [6, 18], [7, 17], [7, 19], [...   \n",
              "...                                                                                                    ...   \n",
              "25019  [[0, 8], [0, 14], [1, 10], [2, 12], [3, 13], [4, 7], [5, 7], [6, 8], [6, 9], [6, 15], [7, 18], [...   \n",
              "25020  [[0, 9], [1, 11], [2, 16], [2, 19], [3, 16], [4, 15], [5, 18], [6, 7], [6, 8], [6, 13], [7, 10],...   \n",
              "25021  [[0, 12], [0, 16], [1, 10], [2, 11], [3, 15], [4, 16], [5, 17], [6, 18], [6, 27], [7, 20], [8, 2...   \n",
              "25022  [[0, 11], [0, 12], [1, 21], [1, 27], [2, 22], [2, 28], [3, 21], [4, 22], [5, 8], [5, 12], [6, 13...   \n",
              "25023  [[0, 25], [1, 26], [2, 29], [3, 13], [3, 15], [4, 14], [5, 24], [6, 12], [7, 12], [8, 13], [8, 1...   \n",
              "\n",
              "       label  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "...      ...  \n",
              "25019      0  \n",
              "25020      0  \n",
              "25021      0  \n",
              "25022      0  \n",
              "25023      0  \n",
              "\n",
              "[25024 rows x 3 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0junmqEWELr",
        "outputId": "66dba27f-bc45-4dc5-fc2d-c81197ac9583"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    23806\n",
              "1     1218\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.label.value_counts()\n",
        "# data is imbalanced I will handle it by class weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eutfUdw3UcbN"
      },
      "source": [
        "## Data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OwaVXiDLUeeM"
      },
      "outputs": [],
      "source": [
        "# split data into train & validation by 85 to 15 \n",
        "training_set, validation_set = train_test_split(train, test_size=0.15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaFgCiRSaFP2"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SHKU_ZVGlxpW"
      },
      "outputs": [],
      "source": [
        "all_nodes = [s[0] for s in training_set]\n",
        "# get max length of nodes\n",
        "longest = 0\n",
        "for value in all_nodes:\n",
        "    longest = max(longest, len(value))                                                                                                                                                                                                                             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7iiHlI4EaIhw"
      },
      "outputs": [],
      "source": [
        "max_vocab = 700\n",
        "max_len = longest  # max number of nodes in a molecules\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=max_vocab)\n",
        "tokenizer.fit_on_texts(all_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yKopo0zwmwi4"
      },
      "outputs": [],
      "source": [
        "# A function to prepare single batch\n",
        "def prepare_single_batch(samples): # samples parameter = a list of samples (molecules)\n",
        " # extract nodes symbols from each sample \n",
        "    sample_nodes = [s[0] for s in samples]  \n",
        "# tokenize nodes                   \n",
        "    sample_nodes = tokenizer.texts_to_sequences(sample_nodes)   \n",
        "# pad_sequences for post padding the nodes\n",
        "    sample_nodes = pad_sequences(sample_nodes, padding='post')  \n",
        "# max length of nodes \n",
        "    max_nodes_len = np.shape(sample_nodes)[1]                   \n",
        "#  edges\n",
        "    edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)] \n",
        "    edges = [e for e in edges if len(e) > 0]\n",
        "# segmented_ids array\n",
        "    node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]  \n",
        "    all_nodes = np.reshape(sample_nodes, -1)  \n",
        "# concatenate the edges as size [total_edges ,2]\n",
        "    all_edges = np.concatenate(edges)         \n",
        "# which node belong to which graph\n",
        "    node_to_graph = np.reshape(node_to_graph, -1)\n",
        "# returns a dictionary of features(data,edges,node2grah) and label\n",
        "    return {\n",
        "        'data': all_nodes,\n",
        "        'edges': all_edges,\n",
        "        'node2grah': node_to_graph,\n",
        "    }, np.array([s[2] for s in samples]) \n",
        "\n",
        "\n",
        "# A function to generate batch with given batch_size\n",
        "def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n",
        "    while True:  \n",
        "      # put dataset in a list to shuffle it              \n",
        "        dataset = list(dataset) \n",
        "        if shuffle:             \n",
        "            random.shuffle(dataset) \n",
        "        l = len(dataset)  \n",
        "        for ndx in range(0, l, batch_size):  \n",
        "            batch_samples = dataset[ndx:min(ndx + batch_size, l)] \n",
        "            yield prepare_single_batch(batch_samples)  \n",
        "        if not repeat:  \n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoPKT5lcVi4P",
        "outputId": "a4966a9d-4b85-470e-9a45-28e7d599c251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data\n",
            "[2 2 2 2 2 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 2 2 3 3 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 5 2 2 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 5 5 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "edges\n",
            "[[ 0  7]\n",
            " [ 1 10]\n",
            " [ 2 16]\n",
            " [ 3  6]\n",
            " [ 4  6]\n",
            " [ 5 10]\n",
            " [ 5 11]\n",
            " [ 6 17]\n",
            " [ 7  8]\n",
            " [ 7  9]\n",
            " [ 7 10]\n",
            " [ 8 11]\n",
            " [ 8 15]\n",
            " [ 9 12]\n",
            " [ 9 14]\n",
            " [11 18]\n",
            " [12 13]\n",
            " [12 19]\n",
            " [13 16]\n",
            " [13 21]\n",
            " [14 16]\n",
            " [15 17]\n",
            " [17 20]\n",
            " [18 20]\n",
            " [19 22]\n",
            " [21 23]\n",
            " [22 23]\n",
            " [26 38]\n",
            " [26 44]\n",
            " [27 37]\n",
            " [28 43]\n",
            " [29 33]\n",
            " [29 34]\n",
            " [30 41]\n",
            " [30 43]\n",
            " [31 32]\n",
            " [31 33]\n",
            " [31 36]\n",
            " [32 34]\n",
            " [32 39]\n",
            " [33 35]\n",
            " [34 37]\n",
            " [35 38]\n",
            " [36 40]\n",
            " [37 42]\n",
            " [38 40]\n",
            " [39 41]\n",
            " [43 45]\n",
            " [52 75]\n",
            " [53 62]\n",
            " [54 66]\n",
            " [55 60]\n",
            " [55 61]\n",
            " [55 62]\n",
            " [56 60]\n",
            " [56 65]\n",
            " [57 58]\n",
            " [57 64]\n",
            " [58 72]\n",
            " [59 69]\n",
            " [60 63]\n",
            " [61 65]\n",
            " [61 67]\n",
            " [62 64]\n",
            " [63 66]\n",
            " [63 69]\n",
            " [64 66]\n",
            " [65 68]\n",
            " [67 70]\n",
            " [68 71]\n",
            " [70 71]\n",
            " [72 73]\n",
            " [72 74]\n",
            " [73 76]\n",
            " [74 77]\n",
            " [75 76]\n",
            " [75 77]\n",
            " [78 95]\n",
            " [79 96]\n",
            " [80 81]\n",
            " [80 91]\n",
            " [81 85]\n",
            " [81 86]\n",
            " [81 87]\n",
            " [82 85]\n",
            " [82 88]\n",
            " [82 89]\n",
            " [83 86]\n",
            " [83 88]\n",
            " [83 90]\n",
            " [84 87]\n",
            " [84 89]\n",
            " [84 90]\n",
            " [91 92]\n",
            " [92 93]\n",
            " [92 94]\n",
            " [93 96]\n",
            " [94 95]\n",
            " [95 97]\n",
            " [96 97]]\n",
            "node2grah\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
            "label [0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# showing one batch:\n",
        "for train_batch in gen_batch(training_set, batch_size=4):\n",
        "    for k,v in train_batch[0].items():\n",
        "        print(k)\n",
        "        print(v)\n",
        "        pass\n",
        "    print('label', train_batch[1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qh-UeRcW9NE"
      },
      "source": [
        "## Trials\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qbjt7LXtWyaV"
      },
      "outputs": [],
      "source": [
        "# A function to save the submission files\n",
        "def saveResult(y_pred, fileName):\n",
        "  submission = pd.DataFrame({'label': y_pred})\n",
        "  submission.index.name = 'id'\n",
        "  \n",
        "  submission.to_csv(fileName)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyjxRZvKbIet"
      },
      "source": [
        "### Trial 0 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXdzTdObd7dY",
        "outputId": "06d36939-1609-4367-937e-51170dc42dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 20)           14000       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " gnn (GNN)                      (None, 32)           22464       ['embedding[0][0]',              \n",
            "                                                                  'input_2[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n",
            " da)                                                              'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 36,497\n",
            "Trainable params: 36,497\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model Building \n",
        "\n",
        "# Nodes Input layer \n",
        "data = keras.Input(batch_shape=(None,))  \n",
        "\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "# Edge Input layer\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "# node2graph Input layer\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "# Embedding layer \n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# GNNInput takes the features of sample ( node, the edge, the created list 'node2graph', and number of graphs (number of samples))\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "\n",
        "# defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "\n",
        "# Computes the segmented mean based on segment_ids\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "# output layer\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "\n",
        "# model building\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "# summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BniJDF3hd7fy"
      },
      "outputs": [],
      "source": [
        "# Model Compiling \n",
        "model.compile( optimizer='adam',\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEaKKmE5d7iQ",
        "outputId": "4b322676-cbee-4c2a-887b-c9d95003f1cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1330/1330 [==============================] - 24s 18ms/step - loss: 0.1772 - auc: 0.7033 - val_loss: 0.1947 - val_auc: 0.7418\n",
            "Epoch 2/15\n",
            "1330/1330 [==============================] - 27s 20ms/step - loss: 0.1766 - auc: 0.7064 - val_loss: 0.1822 - val_auc: 0.7537\n",
            "Epoch 3/15\n",
            "1330/1330 [==============================] - 28s 21ms/step - loss: 0.1761 - auc: 0.7184 - val_loss: 0.2047 - val_auc: 0.7296\n",
            "Epoch 4/15\n",
            "1330/1330 [==============================] - 23s 17ms/step - loss: 0.1744 - auc: 0.7263 - val_loss: 0.1769 - val_auc: 0.7324\n",
            "Epoch 5/15\n",
            "1330/1330 [==============================] - 25s 19ms/step - loss: 0.1740 - auc: 0.7236 - val_loss: 0.1926 - val_auc: 0.7475\n",
            "Epoch 6/15\n",
            "1330/1330 [==============================] - 27s 20ms/step - loss: 0.1736 - auc: 0.7243 - val_loss: 0.1862 - val_auc: 0.7405\n",
            "Epoch 7/15\n",
            "1330/1330 [==============================] - 26s 19ms/step - loss: 0.1720 - auc: 0.7429 - val_loss: 0.1781 - val_auc: 0.7476\n",
            "Epoch 8/15\n",
            "1330/1330 [==============================] - 33s 25ms/step - loss: 0.1723 - auc: 0.7403 - val_loss: 0.1867 - val_auc: 0.7573\n",
            "Epoch 9/15\n",
            "1330/1330 [==============================] - 31s 23ms/step - loss: 0.1734 - auc: 0.7324 - val_loss: 0.1802 - val_auc: 0.7571\n",
            "Epoch 10/15\n",
            "1330/1330 [==============================] - 27s 21ms/step - loss: 0.1706 - auc: 0.7523 - val_loss: 0.1820 - val_auc: 0.7632\n",
            "Epoch 11/15\n",
            "1330/1330 [==============================] - 27s 20ms/step - loss: 0.1708 - auc: 0.7454 - val_loss: 0.1954 - val_auc: 0.7457\n",
            "Epoch 12/15\n",
            "1330/1330 [==============================] - 26s 19ms/step - loss: 0.1716 - auc: 0.7442 - val_loss: 0.1804 - val_auc: 0.7702\n",
            "Epoch 13/15\n",
            "1330/1330 [==============================] - 36s 27ms/step - loss: 0.1704 - auc: 0.7532 - val_loss: 0.1762 - val_auc: 0.7666\n",
            "Epoch 14/15\n",
            "1330/1330 [==============================] - 31s 24ms/step - loss: 0.1705 - auc: 0.7494 - val_loss: 0.1816 - val_auc: 0.7674\n",
            "Epoch 15/15\n",
            "1330/1330 [==============================] - 33s 25ms/step - loss: 0.1682 - auc: 0.7587 - val_loss: 0.1749 - val_auc: 0.7660\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45e0f2de40>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "batch_size = 16\n",
        "# math.ceil: to get the nearest integer of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "# num of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "# model training\n",
        "model.fit(\n",
        "    gen_batch(training_set, batch_size = batch_size, repeat=True),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs=15,\n",
        "    validation_data = gen_batch(validation_set, batch_size = batch_size, repeat=True),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfkQ7Nt4d7ka",
        "outputId": "b9595f18-a5fa-4d87-a8ec-d88c2f959451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "771/771 [==============================] - 7s 8ms/step\n"
          ]
        }
      ],
      "source": [
        "# predictions on test data\n",
        "y_pred = model.predict(gen_batch(test, batch_size=16, shuffle=False))\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "l8qMh97Wd7mj"
      },
      "outputs": [],
      "source": [
        "# submission file\n",
        "saveResult(y_pred, 'trial0.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NseicZrXA75"
      },
      "source": [
        "> Thoughts and observations for trial 0: \n",
        "\n",
        "I used **Graph Neural Network** with :\n",
        "\n",
        "* NO data balance techniques \n",
        "* A GNN layer with defualt hyperparameters.\n",
        "* `hidden_dim` = 32 (size of the output of all message passing layers)\n",
        "* another GNN layer with the defined hyperparameters and calculated segmented mean based on segment_ids\n",
        "* model compiling : \n",
        "  - BinaryCrossentropy for loss \n",
        "  - AUC to measure the model's performance.\n",
        "\n",
        "\n",
        "In the training:\n",
        "* batch size = 16 \n",
        "* epochs = 15 \n",
        "* validated the model using the `validation_set`\n",
        "\n",
        "From the result, unbalanced data had a bad effect on the model's accuracy and cause bad performance.\n",
        "\n",
        "> plan for trial 1: \n",
        "\n",
        "apply a data balance technichque (class weighting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO14-7s3lyzJ"
      },
      "source": [
        "### Trial 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCgvv3Ial0gw",
        "outputId": "db3621d4-efd7-4a6f-ebde-7c1108c4087f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1330/1330 [==============================] - 31s 21ms/step - loss: 1.1940 - auc: 0.7141 - val_loss: 0.6457 - val_auc: 0.7334\n",
            "Epoch 2/15\n",
            "1330/1330 [==============================] - 23s 18ms/step - loss: 1.1410 - auc: 0.7427 - val_loss: 0.5629 - val_auc: 0.7417\n",
            "Epoch 3/15\n",
            "1330/1330 [==============================] - 27s 21ms/step - loss: 1.1250 - auc: 0.7522 - val_loss: 0.5504 - val_auc: 0.7466\n",
            "Epoch 4/15\n",
            "1330/1330 [==============================] - 24s 18ms/step - loss: 1.1164 - auc: 0.7581 - val_loss: 0.6274 - val_auc: 0.7514\n",
            "Epoch 5/15\n",
            "1330/1330 [==============================] - 31s 23ms/step - loss: 1.1124 - auc: 0.7613 - val_loss: 0.5293 - val_auc: 0.7590\n",
            "Epoch 6/15\n",
            "1330/1330 [==============================] - 32s 24ms/step - loss: 1.1031 - auc: 0.7710 - val_loss: 0.6155 - val_auc: 0.7664\n",
            "Epoch 7/15\n",
            "1330/1330 [==============================] - 34s 25ms/step - loss: 1.0871 - auc: 0.7761 - val_loss: 0.6255 - val_auc: 0.7618\n",
            "Epoch 8/15\n",
            "1330/1330 [==============================] - 28s 21ms/step - loss: 1.0928 - auc: 0.7724 - val_loss: 0.5611 - val_auc: 0.7756\n",
            "Epoch 9/15\n",
            "1330/1330 [==============================] - 25s 19ms/step - loss: 1.0853 - auc: 0.7738 - val_loss: 0.5844 - val_auc: 0.7572\n",
            "Epoch 10/15\n",
            "1330/1330 [==============================] - 32s 24ms/step - loss: 1.0875 - auc: 0.7769 - val_loss: 0.6165 - val_auc: 0.7565\n",
            "Epoch 11/15\n",
            "1330/1330 [==============================] - 34s 26ms/step - loss: 1.0835 - auc: 0.7766 - val_loss: 0.5580 - val_auc: 0.7793\n",
            "Epoch 12/15\n",
            "1330/1330 [==============================] - 29s 22ms/step - loss: 1.0836 - auc: 0.7789 - val_loss: 0.5784 - val_auc: 0.7603\n",
            "Epoch 13/15\n",
            "1330/1330 [==============================] - 36s 27ms/step - loss: 1.0788 - auc: 0.7813 - val_loss: 0.4968 - val_auc: 0.7845\n",
            "Epoch 14/15\n",
            "1330/1330 [==============================] - 31s 23ms/step - loss: 1.0618 - auc: 0.7925 - val_loss: 0.5012 - val_auc: 0.7726\n",
            "Epoch 15/15\n",
            "1330/1330 [==============================] - 27s 20ms/step - loss: 1.0618 - auc: 0.7920 - val_loss: 0.4402 - val_auc: 0.7864\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45ced57d60>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "batch_size = 16\n",
        "# math.ceil: to get the nearest integer of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "# num of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "# model training\n",
        "model.fit(\n",
        "    gen_batch(training_set, batch_size = batch_size, repeat=True),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs=15,\n",
        "    validation_data = gen_batch(validation_set, batch_size = batch_size, repeat=True),\n",
        "    validation_steps = num_batchs_validation,\n",
        "    class_weight = {0: 1, 1: 20},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGdPJEJJmhjU",
        "outputId": "201ccb4e-f511-49ab-b2fc-e41cc61317df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "771/771 [==============================] - 6s 8ms/step\n"
          ]
        }
      ],
      "source": [
        "# predictions on test data\n",
        "y_pred = model.predict(gen_batch(test, batch_size=16, shuffle=False))\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6zbBTSp-p2s_"
      },
      "outputs": [],
      "source": [
        "# submission file\n",
        "saveResult(y_pred, 'trial1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAoL748Qo5eo"
      },
      "source": [
        "> Thoughts and observations for trial 1: \n",
        "(the same model)\n",
        "I used **Graph Neural Network** with :\n",
        "\n",
        "* A GNN layer with defualt hyperparameters.\n",
        "* `hidden_dim` = 32 (size of the output of all message passing layers)\n",
        "* another GNN layer with the defined hyperparameters and calculated segmented mean based on segment_ids\n",
        "* model compiling : \n",
        "  - BinaryCrossentropy for loss \n",
        "  - AUC to measure the model's performance.\n",
        "\n",
        "\n",
        "In the training:\n",
        "* batch size = 16 \n",
        "* epochs = 15 \n",
        "* validated the model using the `validation_set`\n",
        "* added the class weights while training to deal with data imbalance\n",
        "\n",
        "From the result, after we applied the calss weighting to balance data the performance got better results that the first model.\n",
        "\n",
        "> plan for trial 2: \n",
        "\n",
        "* add the class weight to all the upcoming trial \n",
        "* Try to apply one of the GCN aggregation mechanisms by tuning the message_passing mechanisms and configure the message passing style to be GGNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km-eCvaErder"
      },
      "source": [
        "### Trial 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--EZA2hQrcjo",
        "outputId": "e7e7b4fa-41bf-4d9f-86c1-88a990230568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_1/StatefulPartitionedCall:0', description=\"created by layer 'gnn_1'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_1/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_1'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_1/Sigmoid:0', description=\"created by layer 'dense_1'\")\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['input_6[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 20)           14000       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.reduce_max_1[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_1 (GNN)                    (None, 32)           47808       ['embedding_1[0][0]',            \n",
            "                                                                  'input_5[0][0]',                \n",
            "                                                                  'input_6[0][0]',                \n",
            "                                                                  'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_1 (TFOpLa  (None, 32)          0           ['gnn_1[0][0]',                  \n",
            " mbda)                                                            'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            33          ['tf.math.segment_mean_1[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 61,841\n",
            "Trainable params: 61,841\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model Building \n",
        "\n",
        "# Nodes Input layer \n",
        "data = keras.Input(batch_shape=(None,))  \n",
        "\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "# Edge Input layer\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "# node2graph Input layer\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "# Embedding layer \n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# GNNInput takes the features of sample ( node, the edge, the created list 'node2graph', and number of graphs (number of samples))\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "\n",
        "# defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the message passing style to be GGNN (Gated Graph Neural Networks)\n",
        "params['message_calculation_class'] = 'GGNN'\n",
        "\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "\n",
        "# Computes the segmented mean based on segment_ids\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "# output layer\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "\n",
        "# model building\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "# summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lZutNb8zruoV"
      },
      "outputs": [],
      "source": [
        "# Model Compiling \n",
        "model.compile( optimizer='adam',\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NPorJsbruq9",
        "outputId": "8426634e-9aa9-4b47-a30f-605159da9141"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1330/1330 [==============================] - 43s 32ms/step - loss: 1.0608 - auc: 0.7861 - val_loss: 0.6621 - val_auc: 0.7689\n",
            "Epoch 2/15\n",
            "1330/1330 [==============================] - 42s 32ms/step - loss: 1.0561 - auc: 0.7879 - val_loss: 0.5049 - val_auc: 0.7885\n",
            "Epoch 3/15\n",
            "1330/1330 [==============================] - 40s 30ms/step - loss: 1.0405 - auc: 0.7976 - val_loss: 0.6012 - val_auc: 0.7963\n",
            "Epoch 4/15\n",
            "1330/1330 [==============================] - 40s 30ms/step - loss: 1.0391 - auc: 0.7983 - val_loss: 0.5965 - val_auc: 0.7573\n",
            "Epoch 5/15\n",
            "1330/1330 [==============================] - 47s 35ms/step - loss: 1.0610 - auc: 0.7859 - val_loss: 0.5175 - val_auc: 0.7948\n",
            "Epoch 6/15\n",
            "1330/1330 [==============================] - 47s 35ms/step - loss: 1.0406 - auc: 0.7973 - val_loss: 0.5993 - val_auc: 0.7709\n",
            "Epoch 7/15\n",
            "1330/1330 [==============================] - 47s 35ms/step - loss: 1.0289 - auc: 0.8003 - val_loss: 0.4822 - val_auc: 0.7936\n",
            "Epoch 8/15\n",
            "1330/1330 [==============================] - 54s 41ms/step - loss: 1.0250 - auc: 0.8037 - val_loss: 0.4640 - val_auc: 0.7832\n",
            "Epoch 9/15\n",
            "1330/1330 [==============================] - 39s 29ms/step - loss: 1.0326 - auc: 0.8000 - val_loss: 0.4705 - val_auc: 0.7916\n",
            "Epoch 10/15\n",
            "1330/1330 [==============================] - 49s 37ms/step - loss: 1.0197 - auc: 0.8069 - val_loss: 0.4306 - val_auc: 0.8223\n",
            "Epoch 11/15\n",
            "1330/1330 [==============================] - 44s 33ms/step - loss: 1.0042 - auc: 0.8125 - val_loss: 0.6027 - val_auc: 0.7907\n",
            "Epoch 12/15\n",
            "1330/1330 [==============================] - 49s 37ms/step - loss: 0.9868 - auc: 0.8214 - val_loss: 0.4317 - val_auc: 0.7980\n",
            "Epoch 13/15\n",
            "1330/1330 [==============================] - 42s 31ms/step - loss: 1.0019 - auc: 0.8155 - val_loss: 0.4521 - val_auc: 0.8313\n",
            "Epoch 14/15\n",
            "1330/1330 [==============================] - 53s 40ms/step - loss: 0.9842 - auc: 0.8230 - val_loss: 0.4768 - val_auc: 0.8141\n",
            "Epoch 15/15\n",
            "1330/1330 [==============================] - 42s 32ms/step - loss: 0.9832 - auc: 0.8222 - val_loss: 0.4993 - val_auc: 0.8179\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45cd4ebdc0>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "batch_size = 16\n",
        "# math.ceil: to get the nearest integer of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "# num of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "# model training\n",
        "model.fit(\n",
        "    gen_batch(training_set, batch_size = batch_size, repeat=True),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs=15,\n",
        "    validation_data = gen_batch(validation_set, batch_size = batch_size, repeat=True),\n",
        "    validation_steps = num_batchs_validation,\n",
        "    class_weight = {0: 1, 1: 20},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl981I_mrutz",
        "outputId": "691dbf78-2be3-43a2-aaaa-3f0f41300dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "771/771 [==============================] - 7s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "# predictions on test data\n",
        "y_pred = model.predict(gen_batch(test, batch_size=16, shuffle=False))\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "6UVXEbGiv5vX"
      },
      "outputs": [],
      "source": [
        "# submission file\n",
        "saveResult(y_pred, 'trial2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPNj9VsFru5d"
      },
      "source": [
        "> Thoughts and observations for trial 2: \n",
        "\n",
        "I used **Graph Neural Network** with :\n",
        "\n",
        "* A GNN layer with defualt hyperparameters.\n",
        "* `hidden_dim` = 32 (size of the output of all message passing layers)\n",
        "* another GNN layer with the defined hyperparameters and calculated segmented mean based on segment_ids\n",
        "* GCN aggregation mechanisms by tuning the message_passing mechanisms and set `message_calculation_class` parameter  = `GGNN`\n",
        "\n",
        "\n",
        "* model compiling : \n",
        "  - BinaryCrossentropy for loss \n",
        "  - AUC to measure the model's performance.\n",
        "\n",
        "\n",
        "In the training:\n",
        "* batch size = 16 \n",
        "* epochs = 15 \n",
        "* validated the model using the `validation_set`\n",
        "* added the class weights while training to deal with data imbalance\n",
        "\n",
        "From the result, findings are far superior to utilizing the model without GCN aggregation methods.\n",
        "\n",
        "> plan for trial 3: \n",
        "\n",
        "* Try to apply another one of the GCN aggregation mechanisms by tuning the message_passing mechanisms and configure the message passing style to be RGCN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxBqFhp31hdT"
      },
      "source": [
        "### Trial 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikHueZZL1kM_",
        "outputId": "980b14f0-8561-4f83-d943-5fa6298d1ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_6/StatefulPartitionedCall:0', description=\"created by layer 'gnn_6'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_6/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_6'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_6/Sigmoid:0', description=\"created by layer 'dense_6'\")\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_21 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_19 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_6 (TFOpLamb  ()                  0           ['input_21[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_6 (Embedding)        (None, 20)           14000       ['input_19[0][0]']               \n",
            "                                                                                                  \n",
            " input_20 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  ()                  0           ['tf.math.reduce_max_6[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_6 (GNN)                    (None, 32)           22464       ['embedding_6[0][0]',            \n",
            "                                                                  'input_20[0][0]',               \n",
            "                                                                  'input_21[0][0]',               \n",
            "                                                                  'tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_6 (TFOpLa  (None, 32)          0           ['gnn_6[0][0]',                  \n",
            " mbda)                                                            'input_21[0][0]']               \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            33          ['tf.math.segment_mean_6[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 36,497\n",
            "Trainable params: 36,497\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model Building \n",
        "\n",
        "# Nodes Input layer \n",
        "data = keras.Input(batch_shape=(None,))  \n",
        "\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "# Edge Input layer\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "# node2graph Input layer\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "# Embedding layer \n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# GNNInput takes the features of sample ( node, the edge, the created list 'node2graph', and number of graphs (number of samples))\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "\n",
        "# defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the message passing style to be RGCN (Relational Graph Convolutional Networks)\n",
        "params['message_calculation_class'] = 'RGCN'\n",
        "\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "\n",
        "# Computes the segmented mean based on segment_ids\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "# output layer\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "\n",
        "# model building\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "# summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "1XceHURo1kPm"
      },
      "outputs": [],
      "source": [
        "# Model Compiling \n",
        "model.compile( optimizer='adam',\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQe04xwC1kRY",
        "outputId": "f7f1ba1b-c5d3-4107-a047-4c486af8dca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1330/1330 [==============================] - 31s 20ms/step - loss: 1.2774 - auc: 0.6201 - val_loss: 0.6746 - val_auc: 0.7054\n",
            "Epoch 2/15\n",
            "1330/1330 [==============================] - 25s 19ms/step - loss: 1.2144 - auc: 0.6875 - val_loss: 0.6444 - val_auc: 0.7406\n",
            "Epoch 3/15\n",
            "1330/1330 [==============================] - 25s 19ms/step - loss: 1.1868 - auc: 0.7099 - val_loss: 0.7274 - val_auc: 0.7320\n",
            "Epoch 4/15\n",
            "1330/1330 [==============================] - 28s 21ms/step - loss: 1.1769 - auc: 0.7122 - val_loss: 0.6005 - val_auc: 0.7450\n",
            "Epoch 5/15\n",
            "1330/1330 [==============================] - 23s 18ms/step - loss: 1.1690 - auc: 0.7189 - val_loss: 0.6411 - val_auc: 0.7574\n",
            "Epoch 6/15\n",
            "1330/1330 [==============================] - 28s 21ms/step - loss: 1.1507 - auc: 0.7326 - val_loss: 0.5606 - val_auc: 0.7491\n",
            "Epoch 7/15\n",
            "1330/1330 [==============================] - 27s 20ms/step - loss: 1.1363 - auc: 0.7421 - val_loss: 0.5302 - val_auc: 0.7524\n",
            "Epoch 8/15\n",
            "1330/1330 [==============================] - 24s 18ms/step - loss: 1.1383 - auc: 0.7449 - val_loss: 0.5558 - val_auc: 0.7695\n",
            "Epoch 9/15\n",
            "1330/1330 [==============================] - 28s 21ms/step - loss: 1.1235 - auc: 0.7476 - val_loss: 0.5901 - val_auc: 0.7662\n",
            "Epoch 10/15\n",
            "1330/1330 [==============================] - 25s 19ms/step - loss: 1.1062 - auc: 0.7613 - val_loss: 0.5684 - val_auc: 0.7646\n",
            "Epoch 11/15\n",
            "1330/1330 [==============================] - 27s 20ms/step - loss: 1.1074 - auc: 0.7610 - val_loss: 0.6109 - val_auc: 0.7842\n",
            "Epoch 12/15\n",
            "1330/1330 [==============================] - 25s 19ms/step - loss: 1.0986 - auc: 0.7629 - val_loss: 0.5583 - val_auc: 0.7808\n",
            "Epoch 13/15\n",
            "1330/1330 [==============================] - 27s 20ms/step - loss: 1.0923 - auc: 0.7695 - val_loss: 0.6094 - val_auc: 0.7841\n",
            "Epoch 14/15\n",
            "1330/1330 [==============================] - 26s 19ms/step - loss: 1.0897 - auc: 0.7715 - val_loss: 0.5975 - val_auc: 0.7839\n",
            "Epoch 15/15\n",
            "1330/1330 [==============================] - 27s 21ms/step - loss: 1.0849 - auc: 0.7731 - val_loss: 0.5995 - val_auc: 0.8144\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45d1e92ec0>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "batch_size = 16\n",
        "# math.ceil: to get the nearest integer of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "# num of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "# model training\n",
        "model.fit(\n",
        "    gen_batch(training_set, batch_size = batch_size, repeat=True),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs=15,\n",
        "    validation_data = gen_batch(validation_set, batch_size = batch_size, repeat=True),\n",
        "    validation_steps = num_batchs_validation,\n",
        "    class_weight = {0: 1, 1: 20},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFad-GDM1kTU",
        "outputId": "87c0f240-9cf4-43d8-96a9-bf7bfc9e8e8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "771/771 [==============================] - 6s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "# predictions on test data\n",
        "y_pred = model.predict(gen_batch(test, batch_size=16, shuffle=False))\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "zXDMhSJK1kVN"
      },
      "outputs": [],
      "source": [
        "# submission file\n",
        "saveResult(y_pred, 'trial3.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NumIhpFNy1fa"
      },
      "source": [
        "> Thoughts and observations for trial 3: \n",
        "\n",
        "I used **Graph Neural Network** with :\n",
        "\n",
        "* A GNN layer with defualt hyperparameters.\n",
        "* `hidden_dim` = 32 (size of the output of all message passing layers)\n",
        "* another GNN layer with the defined hyperparameters and calculated segmented mean based on segment_ids\n",
        "* GCN aggregation mechanisms by tuning the message_passing mechanisms and set `message_calculation_class` parameter  = `RGAT`\n",
        "\n",
        "\n",
        "\n",
        "* model compiling : \n",
        "  - BinaryCrossentropy for loss \n",
        "  - AUC to measure the model's performance.\n",
        "\n",
        "\n",
        "In the training:\n",
        "* batch size = 16 \n",
        "* epochs = 15 \n",
        "* validated the model using the `validation_set`\n",
        "* added the class weights while training to deal with data imbalance\n",
        "\n",
        "> According to the results, the model performs significantly better than when no GCN aggregation techniques are used, but the trail result is lower than when the message_calculation_class option is set to GGNN.\n",
        "\n",
        "> plan for trial 4: \n",
        "\n",
        "* use the same model and set the number of parallel (independent) weighted sums that are computed `num_heads` = 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUE35ZjiyJDb"
      },
      "source": [
        "### Trail 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZadBjLeyMl_",
        "outputId": "4972e2b7-eebf-462f-ec29-e830a0db3b68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_5/StatefulPartitionedCall:0', description=\"created by layer 'gnn_5'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_5/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_5'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_5/Sigmoid:0', description=\"created by layer 'dense_5'\")\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_18 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_16 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_5 (TFOpLamb  ()                  0           ['input_18[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, 20)           14000       ['input_16[0][0]']               \n",
            "                                                                                                  \n",
            " input_17 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  ()                  0           ['tf.math.reduce_max_5[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_5 (GNN)                    (None, 32)           22464       ['embedding_5[0][0]',            \n",
            "                                                                  'input_17[0][0]',               \n",
            "                                                                  'input_18[0][0]',               \n",
            "                                                                  'tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_5 (TFOpLa  (None, 32)          0           ['gnn_5[0][0]',                  \n",
            " mbda)                                                            'input_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            33          ['tf.math.segment_mean_5[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 36,497\n",
            "Trainable params: 36,497\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model Building \n",
        "\n",
        "# Nodes Input layer \n",
        "data = keras.Input(batch_shape=(None,))  \n",
        "\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "# Edge Input layer\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "# node2graph Input layer\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "# Embedding layer \n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# GNNInput takes the features of sample ( node, the edge, the created list 'node2graph', and number of graphs (number of samples))\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "\n",
        "# defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the message passing style to be RGCN (Relational Graph Convolutional Networks)\n",
        "params['message_calculation_class'] = 'RGCN'\n",
        "# configures the number of parallel (independent) weighted sums that are computed, whose results are concatenated to obtain the final result.\n",
        "params[\"num_heads\"] = 4\n",
        "\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "\n",
        "# Computes the segmented mean based on segment_ids\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "# output layer\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "\n",
        "# model building\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "# summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "RgXxuEiUyaDj"
      },
      "outputs": [],
      "source": [
        "# Model Compiling \n",
        "model.compile( optimizer='adam',\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5fcY2iSyaHC",
        "outputId": "b81e131f-65f0-479d-a4bf-5b9bbb12010d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1330/1330 [==============================] - 32s 21ms/step - loss: 1.2763 - auc: 0.6295 - val_loss: 0.6034 - val_auc: 0.6592\n",
            "Epoch 2/15\n",
            "1330/1330 [==============================] - 26s 20ms/step - loss: 1.2178 - auc: 0.6820 - val_loss: 0.7213 - val_auc: 0.7215\n",
            "Epoch 3/15\n",
            "1330/1330 [==============================] - 29s 22ms/step - loss: 1.1655 - auc: 0.7180 - val_loss: 0.5841 - val_auc: 0.7356\n",
            "Epoch 4/15\n",
            "1330/1330 [==============================] - 29s 22ms/step - loss: 1.1626 - auc: 0.7230 - val_loss: 0.6032 - val_auc: 0.7452\n",
            "Epoch 5/15\n",
            "1330/1330 [==============================] - 25s 19ms/step - loss: 1.1489 - auc: 0.7319 - val_loss: 0.6211 - val_auc: 0.7473\n",
            "Epoch 6/15\n",
            "1330/1330 [==============================] - 23s 17ms/step - loss: 1.1537 - auc: 0.7326 - val_loss: 0.6279 - val_auc: 0.7393\n",
            "Epoch 7/15\n",
            "1330/1330 [==============================] - 26s 19ms/step - loss: 1.1440 - auc: 0.7398 - val_loss: 0.5997 - val_auc: 0.7421\n",
            "Epoch 8/15\n",
            "1330/1330 [==============================] - 28s 21ms/step - loss: 1.1379 - auc: 0.7453 - val_loss: 0.6066 - val_auc: 0.7540\n",
            "Epoch 9/15\n",
            "1330/1330 [==============================] - 27s 20ms/step - loss: 1.1319 - auc: 0.7466 - val_loss: 0.6152 - val_auc: 0.7641\n",
            "Epoch 10/15\n",
            "1330/1330 [==============================] - 27s 20ms/step - loss: 1.1133 - auc: 0.7600 - val_loss: 0.5170 - val_auc: 0.7635\n",
            "Epoch 11/15\n",
            "1330/1330 [==============================] - 35s 26ms/step - loss: 1.1190 - auc: 0.7558 - val_loss: 0.5901 - val_auc: 0.7598\n",
            "Epoch 12/15\n",
            "1330/1330 [==============================] - 33s 25ms/step - loss: 1.1151 - auc: 0.7560 - val_loss: 0.5337 - val_auc: 0.7764\n",
            "Epoch 13/15\n",
            "1330/1330 [==============================] - 27s 20ms/step - loss: 1.0927 - auc: 0.7715 - val_loss: 0.5011 - val_auc: 0.7573\n",
            "Epoch 14/15\n",
            "1330/1330 [==============================] - 23s 17ms/step - loss: 1.0988 - auc: 0.7673 - val_loss: 0.6084 - val_auc: 0.7640\n",
            "Epoch 15/15\n",
            "1330/1330 [==============================] - 29s 22ms/step - loss: 1.0928 - auc: 0.7720 - val_loss: 0.5060 - val_auc: 0.7673\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45e10e96c0>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "batch_size = 16\n",
        "# math.ceil: to get the nearest integer of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "# num of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "# model training\n",
        "model.fit(\n",
        "    gen_batch(training_set, batch_size = batch_size, repeat=True),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs=15,\n",
        "    validation_data = gen_batch(validation_set, batch_size = batch_size, repeat=True),\n",
        "    validation_steps = num_batchs_validation,\n",
        "    class_weight = {0: 1, 1: 20},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSOQGR8Bye4V",
        "outputId": "4c371f39-2eb5-46d2-941c-b651a24a0b6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "771/771 [==============================] - 6s 8ms/step\n"
          ]
        }
      ],
      "source": [
        "# predictions on test data\n",
        "y_pred = model.predict(gen_batch(test, batch_size=16, shuffle=False))\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "0AuUxLDuyiXI"
      },
      "outputs": [],
      "source": [
        "# submission file\n",
        "saveResult(y_pred, 'trial4.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP8bjJeV4B_A"
      },
      "source": [
        "> Thoughts and observations for trial 4: \n",
        "\n",
        "I used **Graph Neural Network** with :\n",
        "\n",
        "* A GNN layer with defualt hyperparameters.\n",
        "* `hidden_dim` = 32 (size of the output of all message passing layers)\n",
        "* another GNN layer with the defined hyperparameters and calculated segmented mean based on segment_ids\n",
        "* GCN aggregation mechanisms by tuning the message_passing mechanisms and set `message_calculation_class` parameter  = `RGAT`\n",
        "* set the number of parallel (independent) weighted sums that are computed `num_heads` = 4.\n",
        "\n",
        "\n",
        "\n",
        "* model compiling : \n",
        "  - BinaryCrossentropy for loss \n",
        "  - AUC to measure the model's performance.\n",
        "\n",
        "\n",
        "In the training:\n",
        "* batch size = 16 \n",
        "* epochs = 15 \n",
        "* validated the model using the `validation_set`\n",
        "* added the class weights while training to deal with data imbalance\n",
        "\n",
        "> The results are significantly better than the previous trial in which the message_calculation_class parameter was equal to RGCN, but they are lower than the model in which the message_calculation_class parameter was equal to GGNN.\n",
        "\n",
        "> plan for trial 5: \n",
        "\n",
        "* Try to apply another one of the GCN aggregation mechanisms by tuning the message_passing mechanisms and configure the message passing style to be RGIN, and set the num_aggr_MLP_hidden_layers to be 2 as it is required parameter for RGIN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usSDIKr11K5s"
      },
      "source": [
        "### Trial 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1lH-9ja1MmY",
        "outputId": "daff0dfb-a863-40ab-8edb-ae8b0fcb08c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_7/StatefulPartitionedCall:0', description=\"created by layer 'gnn_7'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_7/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_7'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_7/Sigmoid:0', description=\"created by layer 'dense_7'\")\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_24 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_22 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_7 (TFOpLamb  ()                  0           ['input_24[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_7 (Embedding)        (None, 20)           14000       ['input_22[0][0]']               \n",
            "                                                                                                  \n",
            " input_23 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  ()                  0           ['tf.math.reduce_max_7[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_7 (GNN)                    (None, 32)           34752       ['embedding_7[0][0]',            \n",
            "                                                                  'input_23[0][0]',               \n",
            "                                                                  'input_24[0][0]',               \n",
            "                                                                  'tf.__operators__.add_7[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_7 (TFOpLa  (None, 32)          0           ['gnn_7[0][0]',                  \n",
            " mbda)                                                            'input_24[0][0]']               \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 1)            33          ['tf.math.segment_mean_7[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 48,785\n",
            "Trainable params: 48,785\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model Building \n",
        "\n",
        "# Nodes Input layer \n",
        "data = keras.Input(batch_shape=(None,))  \n",
        "\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "# Edge Input layer\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "# node2graph Input layer\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "# Embedding layer \n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# GNNInput takes the features of sample ( node, the edge, the created list 'node2graph', and number of graphs (number of samples))\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "\n",
        "# defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the message passing style to be RGIN (Relational Graph Isomorphism Networks)\n",
        "params['message_calculation_class'] = 'RGIN'\n",
        "params['num_aggr_MLP_hidden_layers'] = 2\n",
        "\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "\n",
        "# Computes the segmented mean based on segment_ids\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "# output layer\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "\n",
        "# model building\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "# summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "X8iC4zBV7yJF"
      },
      "outputs": [],
      "source": [
        "# Model Compiling \n",
        "model.compile( optimizer='adam',\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEvxfOw27yL-",
        "outputId": "704699b9-ffd0-450c-92de-4a3dccfadc90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1330/1330 [==============================] - 33s 25ms/step - loss: 1.1798 - auc: 0.7169 - val_loss: 0.6047 - val_auc: 0.7771\n",
            "Epoch 2/15\n",
            "1330/1330 [==============================] - 30s 23ms/step - loss: 1.1723 - auc: 0.7204 - val_loss: 0.5462 - val_auc: 0.7224\n",
            "Epoch 3/15\n",
            "1330/1330 [==============================] - 31s 23ms/step - loss: 1.1638 - auc: 0.7259 - val_loss: 0.6338 - val_auc: 0.7669\n",
            "Epoch 4/15\n",
            "1330/1330 [==============================] - 29s 22ms/step - loss: 1.1732 - auc: 0.7237 - val_loss: 0.7083 - val_auc: 0.7477\n",
            "Epoch 5/15\n",
            "1330/1330 [==============================] - 32s 24ms/step - loss: 1.1565 - auc: 0.7337 - val_loss: 0.6347 - val_auc: 0.7360\n",
            "Epoch 6/15\n",
            "1330/1330 [==============================] - 31s 23ms/step - loss: 1.1689 - auc: 0.7307 - val_loss: 0.6907 - val_auc: 0.7442\n",
            "Epoch 7/15\n",
            "1330/1330 [==============================] - 30s 23ms/step - loss: 1.1818 - auc: 0.7136 - val_loss: 0.5425 - val_auc: 0.7049\n",
            "Epoch 8/15\n",
            "1330/1330 [==============================] - 30s 23ms/step - loss: 1.1661 - auc: 0.7247 - val_loss: 0.4540 - val_auc: 0.7515\n",
            "Epoch 9/15\n",
            "1330/1330 [==============================] - 32s 24ms/step - loss: 1.1680 - auc: 0.7264 - val_loss: 0.7067 - val_auc: 0.7272\n",
            "Epoch 10/15\n",
            "1330/1330 [==============================] - 32s 24ms/step - loss: 1.1630 - auc: 0.7246 - val_loss: 0.7271 - val_auc: 0.7469\n",
            "Epoch 11/15\n",
            "1330/1330 [==============================] - 33s 25ms/step - loss: 1.1548 - auc: 0.7353 - val_loss: 0.4729 - val_auc: 0.7289\n",
            "Epoch 12/15\n",
            "1330/1330 [==============================] - 31s 23ms/step - loss: 1.1561 - auc: 0.7338 - val_loss: 0.6278 - val_auc: 0.7416\n",
            "Epoch 13/15\n",
            "1330/1330 [==============================] - 33s 25ms/step - loss: 1.1591 - auc: 0.7356 - val_loss: 0.5383 - val_auc: 0.7421\n",
            "Epoch 14/15\n",
            "1330/1330 [==============================] - 33s 24ms/step - loss: 1.1653 - auc: 0.7285 - val_loss: 0.7538 - val_auc: 0.7514\n",
            "Epoch 15/15\n",
            "1330/1330 [==============================] - 30s 22ms/step - loss: 1.1517 - auc: 0.7349 - val_loss: 0.5711 - val_auc: 0.7619\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45cd929cf0>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "batch_size = 16\n",
        "# math.ceil: to get the nearest integer of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "# num of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "# model training\n",
        "model.fit(\n",
        "    gen_batch(training_set, batch_size = batch_size, repeat=True),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs=15,\n",
        "    validation_data = gen_batch(validation_set, batch_size = batch_size, repeat=True),\n",
        "    validation_steps = num_batchs_validation,\n",
        "    class_weight = {0: 1, 1: 20},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tev7k4079yw",
        "outputId": "965d15be-98f4-4c9b-99b1-cfac6829ebcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "771/771 [==============================] - 7s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "# predictions on test data\n",
        "y_pred = model.predict(gen_batch(test, batch_size=16, shuffle=False))\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "JF6fDT3_79yw"
      },
      "outputs": [],
      "source": [
        "# submission file\n",
        "saveResult(y_pred, 'trial5.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jefVqn9v8Jej"
      },
      "source": [
        "> Thoughts and observations for trial 5: \n",
        "\n",
        "I used **Graph Neural Network** with :\n",
        "\n",
        "* A GNN layer with defualt hyperparameters.\n",
        "* `hidden_dim` = 32 (size of the output of all message passing layers)\n",
        "* another GNN layer with the defined hyperparameters and calculated segmented mean based on segment_ids\n",
        "* GCN aggregation mechanisms by tuning the message_passing mechanisms and set `message_calculation_class` parameter  = `RGIN`\n",
        "* set the `num_aggr_MLP_hidden_layers` = 2\n",
        "\n",
        "\n",
        "\n",
        "* model compiling : \n",
        "  - BinaryCrossentropy for loss \n",
        "  - AUC to measure the model's performance.\n",
        "\n",
        "\n",
        "In the training:\n",
        "* batch size = 16 \n",
        "* epochs = 15 \n",
        "* validated the model using the `validation_set`\n",
        "* added the class weights while training to deal with data imbalance\n",
        "\n",
        "> The results are significantly better than the previous trial in which the message_calculation_class parameter was equal to RGAT, but they are lower than the model in which the message_calculation_class parameter was equal to GGNN.\n",
        "\n",
        "> plan for trial 6: \n",
        "\n",
        "* Try another GCN aggregation mechanisms by tuning the message_passing mechanisms and configure the message passing style to be `GNN_Edge_MLP`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CGAfVqw9Pyw"
      },
      "source": [
        "### Trial 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idFiSONPAAG-",
        "outputId": "762902d3-71e8-4bc2-a739-c18d6d99d311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_8/StatefulPartitionedCall:0', description=\"created by layer 'gnn_8'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_8/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_8'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_8/Sigmoid:0', description=\"created by layer 'dense_8'\")\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_27 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_25 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_8 (TFOpLamb  ()                  0           ['input_27[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_8 (Embedding)        (None, 20)           14000       ['input_25[0][0]']               \n",
            "                                                                                                  \n",
            " input_26 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_8 (TFOpLa  ()                  0           ['tf.math.reduce_max_8[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_8 (GNN)                    (None, 32)           15232       ['embedding_8[0][0]',            \n",
            "                                                                  'input_26[0][0]',               \n",
            "                                                                  'input_27[0][0]',               \n",
            "                                                                  'tf.__operators__.add_8[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_8 (TFOpLa  (None, 32)          0           ['gnn_8[0][0]',                  \n",
            " mbda)                                                            'input_27[0][0]']               \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 1)            33          ['tf.math.segment_mean_8[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 29,265\n",
            "Trainable params: 29,265\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model Building \n",
        "\n",
        "# Nodes Input layer \n",
        "data = keras.Input(batch_shape=(None,))  \n",
        "\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "# Edge Input layer\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "# node2graph Input layer\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "# Embedding layer \n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# GNNInput takes the features of sample ( node, the edge, the created list 'node2graph', and number of graphs (number of samples))\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "\n",
        "#  defualt hyperparameters of GNN_Edge_MLP\n",
        "params = GNN_Edge_MLP.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the parameters that needed by GNN_Edge_MLP\n",
        "params['num_layers'] = 4\n",
        "params['dense_every_num_layers'] = 2\n",
        "params['residual_every_num_layers'] = 2\n",
        "params['use_inter_layer_layernorm'] = 2\n",
        "params['initial_node_representation_activation'] = 'tanh'\n",
        "params['dense_intermediate_layer_activation'] = 'tanh'\n",
        "params['message_calculation_class'] = 'RGCN'\n",
        "params['global_exchange_mode'] = 'gru'   # has to be one of 'mean', 'mlp', 'gru'!\n",
        "params['global_exchange_every_num_layers'] = 1000\n",
        "params['global_exchange_weighting_fun'] = 'softmax'\n",
        "params['global_exchange_num_heads'] = 4\n",
        "params['global_exchange_dropout_rate'] = 0.2\n",
        "params['layer_input_dropout_rate'] = 0.2\n",
        "\n",
        "\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "\n",
        "# Computes the segmented mean based on segment_ids\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "# output layer\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "\n",
        "# model building\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "# summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "TrGXYzZfAAG_"
      },
      "outputs": [],
      "source": [
        "# Model Compiling \n",
        "model.compile( optimizer='adam',\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj8MjssVAAG_",
        "outputId": "708a5e34-1ef7-4c56-9ec8-d804be9f19a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1330/1330 [==============================] - 37s 28ms/step - loss: 1.2396 - auc: 0.6650 - val_loss: 0.6433 - val_auc: 0.7002\n",
            "Epoch 2/15\n",
            "1330/1330 [==============================] - 32s 24ms/step - loss: 1.2259 - auc: 0.6795 - val_loss: 0.6706 - val_auc: 0.6750\n",
            "Epoch 3/15\n",
            "1330/1330 [==============================] - 38s 28ms/step - loss: 1.2205 - auc: 0.6830 - val_loss: 0.5935 - val_auc: 0.6903\n",
            "Epoch 4/15\n",
            "1330/1330 [==============================] - 34s 26ms/step - loss: 1.2114 - auc: 0.6975 - val_loss: 0.6078 - val_auc: 0.7144\n",
            "Epoch 5/15\n",
            "1330/1330 [==============================] - 31s 23ms/step - loss: 1.2141 - auc: 0.6908 - val_loss: 0.4998 - val_auc: 0.6749\n",
            "Epoch 6/15\n",
            "1330/1330 [==============================] - 28s 21ms/step - loss: 1.2022 - auc: 0.6978 - val_loss: 0.5778 - val_auc: 0.7043\n",
            "Epoch 7/15\n",
            "1330/1330 [==============================] - 30s 23ms/step - loss: 1.1869 - auc: 0.7112 - val_loss: 0.5910 - val_auc: 0.7367\n",
            "Epoch 8/15\n",
            "1330/1330 [==============================] - 35s 26ms/step - loss: 1.1627 - auc: 0.7305 - val_loss: 0.6531 - val_auc: 0.7245\n",
            "Epoch 9/15\n",
            "1330/1330 [==============================] - 28s 21ms/step - loss: 1.1623 - auc: 0.7299 - val_loss: 0.6130 - val_auc: 0.7540\n",
            "Epoch 10/15\n",
            "1330/1330 [==============================] - 29s 22ms/step - loss: 1.1465 - auc: 0.7416 - val_loss: 0.5538 - val_auc: 0.7771\n",
            "Epoch 11/15\n",
            "1330/1330 [==============================] - 33s 25ms/step - loss: 1.1465 - auc: 0.7375 - val_loss: 0.5411 - val_auc: 0.7239\n",
            "Epoch 12/15\n",
            "1330/1330 [==============================] - 36s 27ms/step - loss: 1.1427 - auc: 0.7419 - val_loss: 0.5341 - val_auc: 0.8069\n",
            "Epoch 13/15\n",
            "1330/1330 [==============================] - 31s 24ms/step - loss: 1.1267 - auc: 0.7514 - val_loss: 0.5585 - val_auc: 0.7878\n",
            "Epoch 14/15\n",
            "1330/1330 [==============================] - 29s 22ms/step - loss: 1.1096 - auc: 0.7630 - val_loss: 0.6033 - val_auc: 0.7932\n",
            "Epoch 15/15\n",
            "1330/1330 [==============================] - 30s 23ms/step - loss: 1.0971 - auc: 0.7708 - val_loss: 0.6176 - val_auc: 0.7892\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45c8d32470>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "batch_size = 16\n",
        "# math.ceil: to get the nearest integer of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "# num of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "# model training\n",
        "model.fit(\n",
        "    gen_batch(training_set, batch_size = batch_size, repeat=True),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs=15,\n",
        "    validation_data = gen_batch(validation_set, batch_size = batch_size, repeat=True),\n",
        "    validation_steps = num_batchs_validation,\n",
        "    class_weight = {0: 1, 1: 20},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytORVoBCAAG_",
        "outputId": "3c7da829-7cd3-4325-a4c5-154dcb938b75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "771/771 [==============================] - 7s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "# predictions on test data\n",
        "y_pred = model.predict(gen_batch(test, batch_size=16, shuffle=False))\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "dZTW4UdzAAG_"
      },
      "outputs": [],
      "source": [
        "# submission file\n",
        "saveResult(y_pred, 'trial6.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dZG3BJcApQG"
      },
      "source": [
        "> Thoughts and observations for trial 6: \n",
        "\n",
        "I used **Graph Neural Network** with :\n",
        "\n",
        "* A GNN layer with defualt hyperparameters.\n",
        "* `hidden_dim` = 32 (size of the output of all message passing layers)\n",
        "* another GNN layer with the defined hyperparameters and calculated segmented mean based on segment_ids\n",
        "* GCN aggregation mechanisms by tuning the message_passing and configure the message passing style to be `GNN_Edge_MLP`\n",
        "* configure all the parameters that needed by GNN_Edge_MLP\n",
        "\n",
        "\n",
        "* model compiling : \n",
        "  - BinaryCrossentropy for loss \n",
        "  - AUC to measure the model's performance.\n",
        "\n",
        "\n",
        "In the training:\n",
        "* batch size = 16 \n",
        "* epochs = 15 \n",
        "* validated the model using the `validation_set`\n",
        "* added the class weights while training to deal with data imbalance\n",
        "\n",
        "> The results are  better than the previous trials, but they are lower than the model in which the message_calculation_class parameter was equal to GGNN.\n",
        "Till now GGNN has best results\n",
        "\n",
        "> plan for trial 7: \n",
        "\n",
        "* Try another GCN aggregation mechanisms by tuning the message_passing mechanisms and configure the message passing style to be `GNN_FiLM`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IDwoZMPCLhO"
      },
      "source": [
        "### Trial 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nGTEy4yDoyA",
        "outputId": "e84d98a4-9afd-4457-c5df-679167e07ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_9/StatefulPartitionedCall:0', description=\"created by layer 'gnn_9'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_9/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_9'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_9/Sigmoid:0', description=\"created by layer 'dense_9'\")\n",
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_30 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_28 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_9 (TFOpLamb  ()                  0           ['input_30[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_9 (Embedding)        (None, 20)           14000       ['input_28[0][0]']               \n",
            "                                                                                                  \n",
            " input_29 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_9 (TFOpLa  ()                  0           ['tf.math.reduce_max_9[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_9 (GNN)                    (None, 32)           7040        ['embedding_9[0][0]',            \n",
            "                                                                  'input_29[0][0]',               \n",
            "                                                                  'input_30[0][0]',               \n",
            "                                                                  'tf.__operators__.add_9[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_9 (TFOpLa  (None, 32)          0           ['gnn_9[0][0]',                  \n",
            " mbda)                                                            'input_30[0][0]']               \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1)            33          ['tf.math.segment_mean_9[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,073\n",
            "Trainable params: 21,073\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model Building \n",
        "\n",
        "# Nodes Input layer \n",
        "data = keras.Input(batch_shape=(None,))  \n",
        "\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "# Edge Input layer\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "# node2graph Input layer\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "# Embedding layer \n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# GNNInput takes the features of sample ( node, the edge, the created list 'node2graph', and number of graphs (number of samples))\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "\n",
        "#  defualt hyperparameters of GNN_FiLM\n",
        "params = GNN_FiLM.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the parameters that needed by GNN_FiLM\n",
        "params['num_layers'] = 4\n",
        "params['dense_every_num_layers'] = 2\n",
        "params['residual_every_num_layers'] = 2\n",
        "params['use_inter_layer_layernorm'] = 2\n",
        "params['initial_node_representation_activation'] = 'tanh'\n",
        "params['dense_intermediate_layer_activation'] = 'tanh'\n",
        "params['message_calculation_class'] = 'RGCN'\n",
        "params['global_exchange_mode'] = 'gru'   # has to be one of 'mean', 'mlp', 'gru'!\n",
        "params['global_exchange_every_num_layers'] = 1000\n",
        "params['global_exchange_weighting_fun'] = 'softmax'\n",
        "params['global_exchange_num_heads'] = 4\n",
        "params['global_exchange_dropout_rate'] = 0.2\n",
        "params['layer_input_dropout_rate'] = 0.2\n",
        "\n",
        "\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "\n",
        "# Computes the segmented mean based on segment_ids\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "# output layer\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "\n",
        "# model building\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "# summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "nxZOW1jsDoyA"
      },
      "outputs": [],
      "source": [
        "# Model Compiling \n",
        "model.compile( optimizer='adam',\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n80uxQ10DoyB",
        "outputId": "dd6af55f-acfb-459d-a362-8aae3e18b279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1330/1330 [==============================] - 30s 20ms/step - loss: 1.2697 - auc: 0.6372 - val_loss: 0.5955 - val_auc: 0.6791\n",
            "Epoch 2/15\n",
            "1330/1330 [==============================] - 33s 25ms/step - loss: 1.2310 - auc: 0.6725 - val_loss: 0.6323 - val_auc: 0.6972\n",
            "Epoch 3/15\n",
            "1330/1330 [==============================] - 29s 21ms/step - loss: 1.2184 - auc: 0.6843 - val_loss: 0.6163 - val_auc: 0.6910\n",
            "Epoch 4/15\n",
            "1330/1330 [==============================] - 29s 22ms/step - loss: 1.2070 - auc: 0.6945 - val_loss: 0.5495 - val_auc: 0.7233\n",
            "Epoch 5/15\n",
            "1330/1330 [==============================] - 29s 22ms/step - loss: 1.1991 - auc: 0.7044 - val_loss: 0.6225 - val_auc: 0.7276\n",
            "Epoch 6/15\n",
            "1330/1330 [==============================] - 29s 22ms/step - loss: 1.1814 - auc: 0.7146 - val_loss: 0.6505 - val_auc: 0.7437\n",
            "Epoch 7/15\n",
            "1330/1330 [==============================] - 33s 25ms/step - loss: 1.1723 - auc: 0.7219 - val_loss: 0.4608 - val_auc: 0.7521\n",
            "Epoch 8/15\n",
            "1330/1330 [==============================] - 32s 24ms/step - loss: 1.1684 - auc: 0.7285 - val_loss: 0.6390 - val_auc: 0.7424\n",
            "Epoch 9/15\n",
            "1330/1330 [==============================] - 28s 21ms/step - loss: 1.1653 - auc: 0.7265 - val_loss: 0.5682 - val_auc: 0.7548\n",
            "Epoch 10/15\n",
            "1330/1330 [==============================] - 34s 25ms/step - loss: 1.1537 - auc: 0.7346 - val_loss: 0.6490 - val_auc: 0.7482\n",
            "Epoch 11/15\n",
            "1330/1330 [==============================] - 29s 22ms/step - loss: 1.1499 - auc: 0.7366 - val_loss: 0.6774 - val_auc: 0.7623\n",
            "Epoch 12/15\n",
            "1330/1330 [==============================] - 30s 23ms/step - loss: 1.1471 - auc: 0.7405 - val_loss: 0.6642 - val_auc: 0.7325\n",
            "Epoch 13/15\n",
            "1330/1330 [==============================] - 26s 19ms/step - loss: 1.1599 - auc: 0.7323 - val_loss: 0.6065 - val_auc: 0.7478\n",
            "Epoch 14/15\n",
            "1330/1330 [==============================] - 27s 20ms/step - loss: 1.1438 - auc: 0.7398 - val_loss: 0.5631 - val_auc: 0.7413\n",
            "Epoch 15/15\n",
            "1330/1330 [==============================] - 28s 21ms/step - loss: 1.1330 - auc: 0.7458 - val_loss: 0.5527 - val_auc: 0.7623\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45bd403d60>"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "batch_size = 16\n",
        "# math.ceil: to get the nearest integer of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "# num of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "# model training\n",
        "model.fit(\n",
        "    gen_batch(training_set, batch_size = batch_size, repeat=True),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs=15,\n",
        "    validation_data = gen_batch(validation_set, batch_size = batch_size, repeat=True),\n",
        "    validation_steps = num_batchs_validation,\n",
        "    class_weight = {0: 1, 1: 20},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh_iyq7ADoyB",
        "outputId": "4107a61e-dab0-4ef6-e5b6-5ade37ac7c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "771/771 [==============================] - 7s 8ms/step\n"
          ]
        }
      ],
      "source": [
        "# predictions on test data\n",
        "y_pred = model.predict(gen_batch(test, batch_size=16, shuffle=False))\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "h-qgzr6RDoyB"
      },
      "outputs": [],
      "source": [
        "# submission file\n",
        "saveResult(y_pred, 'trial7.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFREmJcNEIwX"
      },
      "source": [
        "> Thoughts and observations for trial 7: \n",
        "\n",
        "I used **Graph Neural Network** with :\n",
        "\n",
        "* A GNN layer with defualt hyperparameters.\n",
        "* `hidden_dim` = 32 (size of the output of all message passing layers)\n",
        "* another GNN layer with the defined hyperparameters and calculated segmented mean based on segment_ids\n",
        "* GCN aggregation mechanisms by tuning the message_passing and configure the message passing style to be `GNN_FiLM`\n",
        "* configure all the parameters that needed by GNN_FiLM\n",
        "\n",
        "\n",
        "* model compiling : \n",
        "  - BinaryCrossentropy for loss \n",
        "  - AUC to measure the model's performance.\n",
        "\n",
        "\n",
        "In the training:\n",
        "* batch size = 16 \n",
        "* epochs = 15 \n",
        "* validated the model using the `validation_set`\n",
        "* added the class weights while training to deal with data imbalance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmlW-GYuCNwg"
      },
      "source": [
        "### Because the preceding trails have covered all possible GCN aggregation mechanisms (aka message_passing mechanisms) used in the graph convolution layer as represented in the Graph Neural Networks documentation: https://github.com/microsoft/tf2-gnn\n",
        "### And, of all trials, the best two that provide the highest accuracy are: Trials 2 and 6\n",
        "### The subsequent and last two trials will take the top models and tweak their hyperparameters to improve accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJSu808JCM2Y"
      },
      "source": [
        "### Trial 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4OWwS1vI6RQ",
        "outputId": "75656936-a4b5-49da-d16c-2173150210e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_10/StatefulPartitionedCall:0', description=\"created by layer 'gnn_10'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_10/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_10'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_10/Sigmoid:0', description=\"created by layer 'dense_10'\")\n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_33 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_31 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_10 (TFOpLam  ()                  0           ['input_33[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_10 (Embedding)       (None, 20)           14000       ['input_31[0][0]']               \n",
            "                                                                                                  \n",
            " input_32 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_10 (TFOpL  ()                  0           ['tf.math.reduce_max_10[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_10 (GNN)                   (None, 64)           171392      ['embedding_10[0][0]',           \n",
            "                                                                  'input_32[0][0]',               \n",
            "                                                                  'input_33[0][0]',               \n",
            "                                                                  'tf.__operators__.add_10[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_10 (TFOpL  (None, 64)          0           ['gnn_10[0][0]',                 \n",
            " ambda)                                                           'input_33[0][0]']               \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 1)            65          ['tf.math.segment_mean_10[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 185,457\n",
            "Trainable params: 185,457\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model Building \n",
        "\n",
        "# Nodes Input layer \n",
        "data = keras.Input(batch_shape=(None,))  \n",
        "\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "# Edge Input layer\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "# node2graph Input layer\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "# Embedding layer \n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# GNNInput takes the features of sample ( node, the edge, the created list 'node2graph', and number of graphs (number of samples))\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "\n",
        "# defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 64\n",
        "# configures the message passing style to be GGNN (Gated Graph Neural Networks)\n",
        "params['message_calculation_class'] = 'GGNN'\n",
        "\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "\n",
        "# Computes the segmented mean based on segment_ids\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "# output layer\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "\n",
        "# model building\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "# summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "-08PxJV-I6RR"
      },
      "outputs": [],
      "source": [
        "# Model Compiling \n",
        "model.compile( optimizer='adam',\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LVfwf7tI6RR",
        "outputId": "ca0ba1a0-960d-449c-9aba-5e8b0070ff0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1330/1330 [==============================] - 85s 59ms/step - loss: 1.2611 - auc: 0.6476 - val_loss: 0.6854 - val_auc: 0.6701\n",
            "Epoch 2/15\n",
            "1330/1330 [==============================] - 87s 65ms/step - loss: 1.2296 - auc: 0.6747 - val_loss: 0.6183 - val_auc: 0.7383\n",
            "Epoch 3/15\n",
            "1330/1330 [==============================] - 99s 74ms/step - loss: 1.1908 - auc: 0.7087 - val_loss: 0.5094 - val_auc: 0.7567\n",
            "Epoch 4/15\n",
            "1330/1330 [==============================] - 89s 67ms/step - loss: 1.1789 - auc: 0.7196 - val_loss: 0.6470 - val_auc: 0.7555\n",
            "Epoch 5/15\n",
            "1330/1330 [==============================] - 69s 52ms/step - loss: 1.1684 - auc: 0.7258 - val_loss: 0.5871 - val_auc: 0.7493\n",
            "Epoch 6/15\n",
            "1330/1330 [==============================] - 71s 53ms/step - loss: 1.1379 - auc: 0.7435 - val_loss: 0.5377 - val_auc: 0.7778\n",
            "Epoch 7/15\n",
            "1330/1330 [==============================] - 69s 52ms/step - loss: 1.1001 - auc: 0.7703 - val_loss: 0.5670 - val_auc: 0.7823\n",
            "Epoch 8/15\n",
            "1330/1330 [==============================] - 69s 52ms/step - loss: 1.1400 - auc: 0.7474 - val_loss: 0.5610 - val_auc: 0.7049\n",
            "Epoch 9/15\n",
            "1330/1330 [==============================] - 68s 51ms/step - loss: 1.1586 - auc: 0.7368 - val_loss: 0.5103 - val_auc: 0.7609\n",
            "Epoch 10/15\n",
            "1330/1330 [==============================] - 69s 52ms/step - loss: 1.1282 - auc: 0.7576 - val_loss: 0.5421 - val_auc: 0.7715\n",
            "Epoch 11/15\n",
            "1330/1330 [==============================] - 70s 53ms/step - loss: 1.1116 - auc: 0.7691 - val_loss: 0.5575 - val_auc: 0.7742\n",
            "Epoch 12/15\n",
            "1330/1330 [==============================] - 83s 62ms/step - loss: 1.0914 - auc: 0.7792 - val_loss: 0.5549 - val_auc: 0.7865\n",
            "Epoch 13/15\n",
            "1330/1330 [==============================] - 70s 52ms/step - loss: 1.0734 - auc: 0.7887 - val_loss: 0.6339 - val_auc: 0.7475\n",
            "Epoch 14/15\n",
            "1330/1330 [==============================] - 68s 51ms/step - loss: 1.0841 - auc: 0.7800 - val_loss: 0.5417 - val_auc: 0.7908\n",
            "Epoch 15/15\n",
            "1330/1330 [==============================] - 74s 55ms/step - loss: 1.0612 - auc: 0.7947 - val_loss: 0.5266 - val_auc: 0.8126\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45b6da57e0>"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "batch_size = 16\n",
        "# math.ceil: to get the nearest integer of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "# num of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "# model training\n",
        "model.fit(\n",
        "    gen_batch(training_set, batch_size = batch_size, repeat=True),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs=15,\n",
        "    validation_data = gen_batch(validation_set, batch_size = batch_size, repeat=True),\n",
        "    validation_steps = num_batchs_validation,\n",
        "    class_weight = {0: 1, 1: 20},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWC5cb_pI6RR",
        "outputId": "fb28fc15-8153-439b-c15c-cd9514ff2965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "771/771 [==============================] - 13s 17ms/step\n"
          ]
        }
      ],
      "source": [
        "# predictions on test data\n",
        "y_pred = model.predict(gen_batch(test, batch_size=16, shuffle=False))\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "De1FiE5pI6RR"
      },
      "outputs": [],
      "source": [
        "# submission file\n",
        "saveResult(y_pred, 'trial8.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FzN6-PoCM5q"
      },
      "source": [
        "> thoughts and observations for trial 8\n",
        "\n",
        "In this trial I used **the same model that used in the trial 2 ** which is **Graph Neural Network with message_passing mechanisms equals to GGNN**\n",
        "after changing its hyperparameter by setting `hidden_dim` = 64 and this contributes to the model's performance improvement\n",
        "\n",
        "\n",
        "As a result,the training took longer time but the fine-tuning hyperparameters yields superior results than trial 2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcZZfgTPCM8V"
      },
      "source": [
        "### Trial 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuY1Dm6hKQOO",
        "outputId": "f1680195-0d94-449f-ef4a-d550069ab295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_11/StatefulPartitionedCall:0', description=\"created by layer 'gnn_11'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_11/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_11'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_11/Sigmoid:0', description=\"created by layer 'dense_11'\")\n",
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_36 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_34 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_11 (TFOpLam  ()                  0           ['input_36[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_11 (Embedding)       (None, 20)           14000       ['input_34[0][0]']               \n",
            "                                                                                                  \n",
            " input_35 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_11 (TFOpL  ()                  0           ['tf.math.reduce_max_11[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_11 (GNN)                   (None, 64)           59136       ['embedding_11[0][0]',           \n",
            "                                                                  'input_35[0][0]',               \n",
            "                                                                  'input_36[0][0]',               \n",
            "                                                                  'tf.__operators__.add_11[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_11 (TFOpL  (None, 64)          0           ['gnn_11[0][0]',                 \n",
            " ambda)                                                           'input_36[0][0]']               \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 1)            65          ['tf.math.segment_mean_11[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 73,201\n",
            "Trainable params: 73,201\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model Building \n",
        "\n",
        "# Nodes Input layer \n",
        "data = keras.Input(batch_shape=(None,))  \n",
        "\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "# Edge Input layer\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "# node2graph Input layer\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "# Embedding layer \n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# GNNInput takes the features of sample ( node, the edge, the created list 'node2graph', and number of graphs (number of samples))\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "\n",
        "#  defualt hyperparameters of GNN_Edge_MLP\n",
        "params = GNN_Edge_MLP.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 64\n",
        "# configures the parameters that needed by GNN_Edge_MLP\n",
        "params['num_layers'] = 4\n",
        "params['dense_every_num_layers'] = 2\n",
        "params['residual_every_num_layers'] = 2\n",
        "params['use_inter_layer_layernorm'] = 2\n",
        "params['initial_node_representation_activation'] = 'tanh'\n",
        "params['dense_intermediate_layer_activation'] = 'tanh'\n",
        "params['message_calculation_class'] = 'RGCN'\n",
        "params['global_exchange_mode'] = 'mlp'   # has to be one of 'mean', 'mlp', 'gru'!\n",
        "params['global_exchange_every_num_layers'] = 1000\n",
        "params['global_exchange_weighting_fun'] = 'softmax'\n",
        "params['global_exchange_num_heads'] = 4\n",
        "params['global_exchange_dropout_rate'] = 0.2\n",
        "params['layer_input_dropout_rate'] = 0.1\n",
        "\n",
        "\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "\n",
        "# Computes the segmented mean based on segment_ids\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "# output layer\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "\n",
        "# model building\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "# summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "Xk5IjMZHKQOO"
      },
      "outputs": [],
      "source": [
        "# Model Compiling \n",
        "model.compile( optimizer='adam',\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNyTeaUaKQOO",
        "outputId": "d5e033dd-a58f-49b1-dfcb-217db82f8878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1330/1330 [==============================] - 52s 36ms/step - loss: 1.2633 - auc: 0.6327 - val_loss: 0.5834 - val_auc: 0.6833\n",
            "Epoch 2/15\n",
            "1330/1330 [==============================] - 49s 37ms/step - loss: 1.2147 - auc: 0.6820 - val_loss: 0.5683 - val_auc: 0.6994\n",
            "Epoch 3/15\n",
            "1330/1330 [==============================] - 52s 39ms/step - loss: 1.2415 - auc: 0.6625 - val_loss: 0.5264 - val_auc: 0.6998\n",
            "Epoch 4/15\n",
            "1330/1330 [==============================] - 48s 36ms/step - loss: 1.2355 - auc: 0.6736 - val_loss: 0.6512 - val_auc: 0.6737\n",
            "Epoch 5/15\n",
            "1330/1330 [==============================] - 48s 36ms/step - loss: 1.2241 - auc: 0.6876 - val_loss: 0.6711 - val_auc: 0.6946\n",
            "Epoch 6/15\n",
            "1330/1330 [==============================] - 47s 36ms/step - loss: 1.2382 - auc: 0.6707 - val_loss: 0.6802 - val_auc: 0.6818\n",
            "Epoch 7/15\n",
            "1330/1330 [==============================] - 48s 36ms/step - loss: 1.2343 - auc: 0.6717 - val_loss: 0.6377 - val_auc: 0.6502\n",
            "Epoch 8/15\n",
            "1330/1330 [==============================] - 50s 38ms/step - loss: 1.2302 - auc: 0.6741 - val_loss: 0.6803 - val_auc: 0.6914\n",
            "Epoch 9/15\n",
            "1330/1330 [==============================] - 46s 35ms/step - loss: 1.2120 - auc: 0.6883 - val_loss: 0.6847 - val_auc: 0.6886\n",
            "Epoch 10/15\n",
            "1330/1330 [==============================] - 48s 36ms/step - loss: 1.2011 - auc: 0.7009 - val_loss: 0.6348 - val_auc: 0.7322\n",
            "Epoch 11/15\n",
            "1330/1330 [==============================] - 51s 38ms/step - loss: 1.1980 - auc: 0.7024 - val_loss: 0.5257 - val_auc: 0.6736\n",
            "Epoch 12/15\n",
            "1330/1330 [==============================] - 55s 42ms/step - loss: 1.2303 - auc: 0.6735 - val_loss: 0.7060 - val_auc: 0.6504\n",
            "Epoch 13/15\n",
            "1330/1330 [==============================] - 53s 40ms/step - loss: 1.2147 - auc: 0.6859 - val_loss: 0.6471 - val_auc: 0.6985\n",
            "Epoch 14/15\n",
            "1330/1330 [==============================] - 57s 43ms/step - loss: 1.1911 - auc: 0.7030 - val_loss: 0.6235 - val_auc: 0.7281\n",
            "Epoch 15/15\n",
            "1330/1330 [==============================] - 49s 37ms/step - loss: 1.1529 - auc: 0.7315 - val_loss: 0.6297 - val_auc: 0.7255\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45b5395d50>"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "batch_size = 16\n",
        "# math.ceil: to get the nearest integer of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "# num of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "# model training\n",
        "model.fit(\n",
        "    gen_batch(training_set, batch_size = batch_size, repeat=True),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs=15,\n",
        "    validation_data = gen_batch(validation_set, batch_size = batch_size, repeat=True),\n",
        "    validation_steps = num_batchs_validation,\n",
        "    class_weight = {0: 1, 1: 20},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3umBkaYfKQOO",
        "outputId": "6d4a0673-efbd-4814-9cf5-e637782a9bbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "771/771 [==============================] - 9s 11ms/step\n"
          ]
        }
      ],
      "source": [
        "# predictions on test data\n",
        "y_pred = model.predict(gen_batch(test, batch_size=16, shuffle=False))\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "Gl_3a1W0KQOO"
      },
      "outputs": [],
      "source": [
        "# submission file\n",
        "saveResult(y_pred, 'trial9.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz5rrfeFCNmb"
      },
      "source": [
        "> thoughts and observations for trial 9:\n",
        "\n",
        "\n",
        "In this trial I used **the same model that used in the trial 6** which is **Graph Neural Network with message_passing mechanisms equals to GNN_Edge_MLP**\n",
        "after changing its hyperparameter by setting `hidden_dim` to be 64 instead of 32 and set `global_exchange_mode` to be 'mlp' instead of 'gru', also set `layer_input_dropout_rate` to be 0.1 instead of 0.2 and found that this help in improving the model result\n",
        "\n",
        "\n",
        "As a result, we can conclude that fine-tuning hyperparameters didin't yield ay better results as excepected, In contrast it yeilds to worse results.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "k8UzJdmzwwtN",
        "QC73uW7J1m8V"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05f72766539c4ef8b618a8875d1d364c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cf1bf1305274760a3ba0eb8247a3d91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "110d35abed8c4a498a7141b6481aa158": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cf1bf1305274760a3ba0eb8247a3d91",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fdf0968e008e4091b47cec0593311c24",
            "value": "100%"
          }
        },
        "226036de4a0a4fc59aa579abc4e21939": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9533476c6fdd4e1fbe32cb14a7a41b5d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ac8f51474ec347589bac8f71968a8eab",
            "value": " 12326/12326 [00:03&lt;00:00, 5920.34it/s]"
          }
        },
        "246971be9b8a40359611a46c7254eef2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4703adaa0e934693ac93ef83cda18391": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a74a20e9a7d8456db86ed91de1dd6315",
            "max": 25024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fb16eaa4319457f9f3551bd96166af7",
            "value": 25024
          }
        },
        "54298f85799a4ba28f42b84b99300550": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5da15f791090436b82d79229096abac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_110d35abed8c4a498a7141b6481aa158",
              "IPY_MODEL_9f542dd37a8e4753948a95d103dc88f4",
              "IPY_MODEL_226036de4a0a4fc59aa579abc4e21939"
            ],
            "layout": "IPY_MODEL_9ee980dc1cb141bcac14e72d53e62300"
          }
        },
        "6c99511dfc7c490b93c30341882dd729": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83de2a2a31d4470abcfd8effb9dde815": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54298f85799a4ba28f42b84b99300550",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e8e8becc624a45b691c188849b485f65",
            "value": "100%"
          }
        },
        "8bab2f05b04e4daa8516dacf906a05c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3862bd8e79a4998b0dda0a2bb723581",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_05f72766539c4ef8b618a8875d1d364c",
            "value": " 25024/25024 [00:04&lt;00:00, 3353.55it/s]"
          }
        },
        "8fb16eaa4319457f9f3551bd96166af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90f08749c2c04066be6f54527a8c37a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9533476c6fdd4e1fbe32cb14a7a41b5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ee980dc1cb141bcac14e72d53e62300": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f542dd37a8e4753948a95d103dc88f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_246971be9b8a40359611a46c7254eef2",
            "max": 12326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c99511dfc7c490b93c30341882dd729",
            "value": 12326
          }
        },
        "a74a20e9a7d8456db86ed91de1dd6315": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a918a40a5f1c4f90a0a3228756b98aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83de2a2a31d4470abcfd8effb9dde815",
              "IPY_MODEL_4703adaa0e934693ac93ef83cda18391",
              "IPY_MODEL_8bab2f05b04e4daa8516dacf906a05c2"
            ],
            "layout": "IPY_MODEL_90f08749c2c04066be6f54527a8c37a0"
          }
        },
        "ac8f51474ec347589bac8f71968a8eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3862bd8e79a4998b0dda0a2bb723581": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8e8becc624a45b691c188849b485f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdf0968e008e4091b47cec0593311c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
